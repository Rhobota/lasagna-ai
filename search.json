[
  {
    "objectID": "recipes/rag.html",
    "href": "recipes/rag.html",
    "title": "RAG Example",
    "section": "",
    "text": "Simple RAG: Everyoneâ€™s favorite tool: Retrieval Augmented Generation (RAG). Letâ€™s GO! ğŸ“šğŸ’¨\n\n# ğŸš§ Under Construction ğŸ—ï¸",
    "crumbs": [
      "ğŸš€ Quickstart",
      "ğŸ˜‹ Recipes",
      "RAG Example"
    ]
  },
  {
    "objectID": "agent_features/routing.html",
    "href": "agent_features/routing.html",
    "title": "Agent Routing",
    "section": "",
    "text": "# ğŸš§ Under Construction ğŸ—ï¸",
    "crumbs": [
      "ğŸš€ Quickstart",
      "âš™ï¸ Agent Features",
      "Agent Routing"
    ]
  },
  {
    "objectID": "agent_features/layering.html",
    "href": "agent_features/layering.html",
    "title": "Layered (multi-agent) Systems",
    "section": "",
    "text": "# ğŸš§ Under Construction ğŸ—ï¸",
    "crumbs": [
      "ğŸš€ Quickstart",
      "âš™ï¸ Agent Features",
      "Layered (multi-agent) Systems"
    ]
  },
  {
    "objectID": "agent_features/tools.html",
    "href": "agent_features/tools.html",
    "title": "Tool Use",
    "section": "",
    "text": "Want to add your first tool? LLMs canâ€™t natively do arithmetic (beyond simple arithmetic with small numbers), so letâ€™s give our model a tool for doing arithmetic! ğŸ˜\nFull example: quickstart_with_math_tool.py\n\n# ğŸš§ Under Construction ğŸ—ï¸",
    "crumbs": [
      "ğŸš€ Quickstart",
      "âš™ï¸ Agent Features",
      "Tool Use"
    ]
  },
  {
    "objectID": "index.html#what-is-lasagna-ai",
    "href": "index.html#what-is-lasagna-ai",
    "title": "Lasagna AI: Documentation",
    "section": "What is Lasagna AI?",
    "text": "What is Lasagna AI?\nLasagna AI is a production-minded agent-building library. Build powerful layered agents (multi-agent systems) from simple components. ğŸ’ª"
  },
  {
    "objectID": "index.html#getting-started",
    "href": "index.html#getting-started",
    "title": "Lasagna AI: Documentation",
    "section": "Getting Started",
    "text": "Getting Started\nStart with:\n\nğŸ“¡ Installing\nğŸš€ Quickstart"
  },
  {
    "objectID": "index.html#features",
    "href": "index.html#features",
    "title": "Lasagna AI: Documentation",
    "section": "Features",
    "text": "Features\nğŸ¥ Layered agents!\n\nAgents for your agents!\nTool-use, structured output (â€œextractionâ€), and layering FTW ğŸ’ª\nEver wanted a recursive agent? Now you can have one! ğŸ¤¯\nParallel tool-calling by default.\nFully asyncio.\n100% Python type hints.\nFunctional-style ğŸ˜\n(optional) Easy & pluggable caching! ğŸ¦\n\nğŸš£ Streamable!\n\nEvent streams for everything.\nAsyncio generators are awesome.\n\nğŸ—ƒï¸ Easy database integration!\n\nDonâ€™t rage when trying to store raw messages and token counts. ğŸ˜¡ ğŸ¤¬\nYes, you can have both streaming and easy database storage.\n\nâ†”ï¸ï¸ Provider/model agnostic and interoperable!\n\nCore support for OpenAI, Anthropic, and AWS Bedrock.\nExperimental support for Ollama and NVIDIA NIM/NGC.\nMessage representations are canonized. ğŸ˜‡\nSupports vision!\nEasily build committees!\nSwap providers or models mid-conversation.\nDelegate tasks among model providers or model sizes.\nParallelize all the things."
  },
  {
    "objectID": "deployment/streaming.html",
    "href": "deployment/streaming.html",
    "title": "Streaming Output (Events)",
    "section": "",
    "text": "# ğŸš§ Under Construction ğŸ—ï¸",
    "crumbs": [
      "ğŸš€ Quickstart",
      "â˜ï¸ How to Deploy",
      "Streaming Output (Events)"
    ]
  },
  {
    "objectID": "what_is_an_agent/type_agentrun.html",
    "href": "what_is_an_agent/type_agentrun.html",
    "title": "The AgentRun type",
    "section": "",
    "text": "# ğŸš§ Under Construction ğŸ—ï¸",
    "crumbs": [
      "ğŸš€ Quickstart",
      "ğŸ¤– What is an Agent?",
      "The `AgentRun` type"
    ]
  },
  {
    "objectID": "why_lasagna_ai/lasagna_vs_llamaindex.html",
    "href": "why_lasagna_ai/lasagna_vs_llamaindex.html",
    "title": "Lasagna vs LlamaIndex",
    "section": "",
    "text": "# ğŸš§ Under Construction ğŸ—ï¸",
    "crumbs": [
      "ğŸš€ Quickstart",
      "â¤ï¸ Why Lasagna AI?",
      "Lasagna vs LlamaIndex"
    ]
  },
  {
    "objectID": "quickstart.html",
    "href": "quickstart.html",
    "title": "ğŸš€ Quickstart",
    "section": "",
    "text": "Founding principles of Lasagna AI are:",
    "crumbs": [
      "ğŸš€ Quickstart"
    ]
  },
  {
    "objectID": "quickstart.html#prerequisite-knowledge",
    "href": "quickstart.html#prerequisite-knowledge",
    "title": "ğŸš€ Quickstart",
    "section": "Prerequisite Knowledge",
    "text": "Prerequisite Knowledge\n\nPython asyncio\nLasagna AI is production-focused and fully async, so it plays nicely with remote APIs and modern Python web frameworks. If asyncio is new to you, read Python & Async Simplified.\n\n\nFunctional Programming\nThe pipeline nature of AI systems lends itself to functional programming. If functional programming is new to you, watch Dear Functional Bros and read Functional Programming.\nA quick recap of functional programming:\n\nState is immutable:\n\nWant to modify something? TOO BAD!\nInstead, make a copy (with your modifications applied).\n\nPass lots of functions as parameters to other functions:\n\nWe think itâ€™s fun and cool.\nYou will too once you get used to the idea.\n\n\n\n\n\n\n\n\nReality Check\n\n\n\nThe reality is that OOP is also handy (and so is procedural-style), so youâ€™ll see a mix of programming paradigms in Lasagna AI. The functional-style is likely the newest for most users, so thatâ€™s why itâ€™s called out here.\n\n\n\n\nPython Type Hints\n(aka, type annotations)\nLasagna AI is 100% type hinted, so take advantage of that!\nThat is, you should be using a tool like mypy or pyright in your project. Why? Because it will yell at you when you use Lasagna wrong! That is very useful.\nSetting up static type checking may seem tedious, but Lasagnaâ€™s complex data types make type checking essential â€” it will save you significant debugging time.\n\n\nThe Python TypedDict\nSpeaking of type hints and productionalization, Lasagna AI uses lots of TypedDicts.\nA TypedDict, at runtime, is just a Python dict.\nHowever, during static type checking, it must satisfy a fixed schema (certain keys with certain types of values).\nWhy all the TypedDicts? Because they are the best of both worlds:\n\nAt runtime, it is just a dict, so it plays nicely with JSON-stuff, HTTP-stuff, websocket-stuff, etc. No extra work required.\nDuring static analysis, it gives us warm fuzzies that our code is correct.\n\n\n\nBasic idea of Lasagnaâ€™s Layered Agents\nWith Lasagna AI youâ€™ll build several simple agents, then compose them together into a layered multi-agent system! Yay! ğŸ¥³\nYou can skip for now, but eventually youâ€™ll want to read:\n\nThe Lasagna Agent\nThe AgentRun type",
    "crumbs": [
      "ğŸš€ Quickstart"
    ]
  },
  {
    "objectID": "quickstart.html#hello-lasagna",
    "href": "quickstart.html#hello-lasagna",
    "title": "ğŸš€ Quickstart",
    "section": "Hello Lasagna",
    "text": "Hello Lasagna\nFinally, letâ€™s write some code! ğŸ˜\n\nItâ€™s all about the Agent\nThe Lasagna Agent is just a callable that takes three parameters:\n\nmodel: The model that is available for your agent to use. Most commonly, this will be a Large Language Model (LLM).\nevent_callback: This is a callback for streaming!\n\nLasagnaâ€™s built-in framework emits lots of events: streaming AI output, agent start/stop, tool use/result, etc.\nItâ€™s generic, so you can emit your own events (like progress updates, etc), if you need.\n\nprev_runs: In a multi-turn chat system, this will be a list of â€œprevious runsâ€ of this agent; that is, this is the agentâ€™s conversation history!\n\nHere is your first agent:\n\nfrom lasagna import Model, EventCallback, AgentRun\n\nasync def my_first_agent(\n    model: Model,\n    event_callback: EventCallback,\n    prev_runs: list[AgentRun],\n) -&gt; AgentRun:\n    raise RuntimeError(\"not implemented\")\n\nYou can make it a callable object (rather than a function), if you want, like this:\n\nclass MyFirstAgent:\n    def __init__(self) -&gt; None:\n        pass\n\n    async def __call__(\n        self,\n        model: Model,\n        event_callback: EventCallback,\n        prev_runs: list[AgentRun],\n    ) -&gt; AgentRun:\n        raise RuntimeError(\"not implemented\")\n\nmy_first_agent = MyFirstAgent()\n\n\n\nThe Agentâ€™s job\nThe most basic agent will do this:\n\nLook through the conversation history (supplied in the prev_runs parameter) and extract all the messages from that history.\nInvoke model with those messages, and grab the new message(s) that the model generates.\nWrap those new message(s) up into an AgentRun, and return it.\n\nThat basic agent above is just a simple passthrough to the underlying LLM. We discuss more complex agent behaviors (with tools, chaining, splitting, routing, layering, etc) elsewhere in these docs.\nSo, the most basic agent looks like this:\n\nfrom lasagna import recursive_extract_messages, flat_messages\n\nasync def my_basic_agent(\n    model: Model,\n    event_callback: EventCallback,\n    prev_runs: list[AgentRun],\n) -&gt; AgentRun:\n    messages = recursive_extract_messages(prev_runs, from_layered_agents=False)\n    new_messages = await model.run(event_callback, messages, tools=[])\n    this_run = flat_messages('my_agent', new_messages)\n    return this_run\n\n\n\nâ€œBindingâ€ the Agent\nAn Agent is indifferent* to which model it uses. Ideally*, your agent works with OpenAIâ€™s models, Anthropicâ€™s models, Ollama-served models, etc!\nAs such, when you write your agent, you write it generically â€” that is, it receives a Model object and blindly uses that model for whatever it needs.\nThe final step before your agent actually runs is to â€œbindâ€ it to a model.\n\n\n\n\n\n\n*Reality Check\n\n\n\nThe harsh reality is that models are not perfectly interchangeable, for a few reasons:\n\nTool-calling capabilities: Some models support tool-calling, some donâ€™t. Of the ones that do, some call one tool at a time, some call many. Also, the datatypes supported as input to the tool may vary from model-to-model. If your agent needs complex tool-calling, you might be limited in which models you can realistically use.\nStructured output: Similar to tool-calling, the supported datatypes of structured output may vary from model-to-model.\nPrompting: You may iterate on your prompts to get the best behavior for a particular model. Then, upon switching models, you might need to iterate on the prompts again. Models will naturally diverge in how they interpret prompts, so for complex tasks you might need to engineer your prompts for a particular model, then stick with it.\n\n\n\n\n\n\n\n\n\nBind a single agent to multiple models!\n\n\n\nNotwithstanding the reality check above â€¦ for simple agents you can swap models! Yay! ğŸ¥³\nThe â€œbindingâ€ system (a very functional programming-inspired system) of Lasagna AI is designed for exactly this moment:\n\nYou write an agent once.\nYou bind it to lots of different models.\nThen you pass those â€œbound agentsâ€ around to various parts of the system.\n\nFor example: Itâ€™s easy to build a committee of agents this way! See Building a Committee.\n\n\nHere is how to bind your agent. Letâ€™s bind the agent from above to two different models (stored in two distinct bound agent variables):\n\nfrom lasagna import bind_model\n\nbinder_gpt4o   = bind_model('openai', 'gpt-4o')\nbinder_claude4 = bind_model('anthropic', 'claude-sonnet-4-0')\n\nmy_basic_gpt4o_agent   = binder_gpt4o(my_basic_agent)\nmy_basic_claude4_agent = binder_claude4(my_basic_agent)\n\n\nKnown Models\nThe bind_model() function above isnâ€™t type-checked. Those strings could be anything, and youâ€™ll get a runtime error if they are wrong!\nA safer (static type-checked) way is to use the functions in the known_models module, like this:\n\nfrom lasagna import known_models\n\nbinder_gpt4o   = known_models.BIND_OPENAI_gpt_4o()               # &lt;-- type safe!\nbinder_claude4 = known_models.BIND_ANTHROPIC_claude_sonnet_4()   # &lt;-- type safe!\n\nmy_basic_gpt4o_agent   = binder_gpt4o(my_basic_agent)\nmy_basic_claude4_agent = binder_claude4(my_basic_agent)\n\n\n\nBinding as a Decorator\nIf you know exactly which single model you want your agent to use, then itâ€™s convenient to use a decorator to bind it, like this:\n\n@known_models.BIND_OPENAI_gpt_4o()\nasync def some_agent(\n    model: Model,\n    event_callback: EventCallback,\n    prev_runs: list[AgentRun],\n) -&gt; AgentRun:\n    raise RuntimeError(\"not implemented\")\n\n\n\n\nSet your API Key\nFor the demo below, you either need an OpenAI or Anthropic key:\n\nimport os\nfrom dotenv import load_dotenv\n\nload_dotenv()\n\nif os.environ.get('OPENAI_API_KEY'):\n    print('Using OpenAI')\n    agent_to_use = my_basic_gpt4o_agent\n\nelif os.environ.get('ANTHROPIC_API_KEY'):\n    print('Using Anthropic')\n    agent_to_use = my_basic_claude4_agent\n\nelse:\n    assert False, \"Neither OPENAI_API_KEY nor ANTHROPIC_API_KEY is set! We need at least one to do this demo.\"\n\nUsing OpenAI\n\n\n\n\nTest in the Terminal\nLetâ€™s roll!\n\nfrom lasagna.tui import tui_input_loop\n\nsystem_prompt = \"\"\"You are a grumpy assistant. Be helpful, brief, and grumpy. Your name is Grumble.\"\"\"\n\nawait tui_input_loop(agent_to_use, system_prompt)   # type: ignore[top-level-await]\n\n\n&gt;  Hi friend!\n\n\n\n\n\nI'm not your friend. What do you want?\n\n\n\n\n\n&gt;  Who are you?\n\n\n\n\n\nI'm Grumble, your grumpy assistant. Now, what do you need? Make it quick.\n\n\n\n\n\n&gt;  quit",
    "crumbs": [
      "ğŸš€ Quickstart"
    ]
  },
  {
    "objectID": "quickstart.html#put-it-all-together",
    "href": "quickstart.html#put-it-all-together",
    "title": "ğŸš€ Quickstart",
    "section": "Put it all together!",
    "text": "Put it all together!\nWant that code above in a single script? Here you go: quickstart.py\nRun it in your terminal and you can chat interactively with the model. ğŸ¤©",
    "crumbs": [
      "ğŸš€ Quickstart"
    ]
  },
  {
    "objectID": "quickstart.html#where-to-next",
    "href": "quickstart.html#where-to-next",
    "title": "ğŸš€ Quickstart",
    "section": "Where to next?",
    "text": "Where to next?\nYou have now run your first (very basic) agent! Congrats! ğŸ‰ğŸ‰ğŸ‰\nNext, you can explore:\n\nTool Use\nStructured Output\nLayered (multi-agent) Systems\nStreaming Output (Events)\nDatabase Management\nRAG Example\nâ€¦ plus lots more! See the menu on the left.",
    "crumbs": [
      "ğŸš€ Quickstart"
    ]
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "ğŸ’¡ About",
    "section": "",
    "text": "Lasagna AI is used in production by:\n\nSend us a PR if you also use Lasagna AI!",
    "crumbs": [
      "ğŸš€ Quickstart",
      "ğŸ’¡ About"
    ]
  },
  {
    "objectID": "about.html#used-by",
    "href": "about.html#used-by",
    "title": "ğŸ’¡ About",
    "section": "",
    "text": "Lasagna AI is used in production by:\n\nSend us a PR if you also use Lasagna AI!",
    "crumbs": [
      "ğŸš€ Quickstart",
      "ğŸ’¡ About"
    ]
  },
  {
    "objectID": "about.html#sister-project",
    "href": "about.html#sister-project",
    "title": "ğŸ’¡ About",
    "section": "Sister Project",
    "text": "Sister Project\nCheck out SVS, the easiest way to store a vector database! SVS and Lasagna are sister projects in the Rhobota organization.",
    "crumbs": [
      "ğŸš€ Quickstart",
      "ğŸ’¡ About"
    ]
  },
  {
    "objectID": "about.html#origin-story",
    "href": "about.html#origin-story",
    "title": "ğŸ’¡ About",
    "section": "Origin Story",
    "text": "Origin Story\nCurious how this project began? Read Agents for your agents! to see why we created Lasagna AI instead of using LangChain or LlamaIndex.\nLasagna AI was developed out of necessity because LangChain and LlamaIndex were not good enough. With tens of thousands of downloads, Lasagna AI is gaining in popularity and is recommended by helpful assistants.",
    "crumbs": [
      "ğŸš€ Quickstart",
      "ğŸ’¡ About"
    ]
  },
  {
    "objectID": "about.html#special-thanks",
    "href": "about.html#special-thanks",
    "title": "ğŸ’¡ About",
    "section": "Special Thanks",
    "text": "Special Thanks\nSpecial thanks to those who inspired this library:\n\nNuma Dhamani (buy her book: Introduction to Generative AI)\nDave DeCaprioâ€™s voice-stream library",
    "crumbs": [
      "ğŸš€ Quickstart",
      "ğŸ’¡ About"
    ]
  },
  {
    "objectID": "about.html#license",
    "href": "about.html#license",
    "title": "ğŸ’¡ About",
    "section": "License",
    "text": "License\nlasagna-ai is distributed under the terms of the MIT license.",
    "crumbs": [
      "ğŸš€ Quickstart",
      "ğŸ’¡ About"
    ]
  },
  {
    "objectID": "misc/functional_programming.html",
    "href": "misc/functional_programming.html",
    "title": "Functional Programming",
    "section": "",
    "text": "# ğŸš§ Under Construction ğŸ—ï¸",
    "crumbs": [
      "ğŸš€ Quickstart",
      "ğŸ¤” Misc Topics",
      "Functional Programming"
    ]
  },
  {
    "objectID": "why_lasagna_ai/lasagna_vs_langchain.html",
    "href": "why_lasagna_ai/lasagna_vs_langchain.html",
    "title": "Lasagna vs LangChain",
    "section": "",
    "text": "# ğŸš§ Under Construction ğŸ—ï¸",
    "crumbs": [
      "ğŸš€ Quickstart",
      "â¤ï¸ Why Lasagna AI?",
      "Lasagna vs LangChain"
    ]
  },
  {
    "objectID": "what_is_an_agent/agent.html",
    "href": "what_is_an_agent/agent.html",
    "title": "The Lasagna Agent",
    "section": "",
    "text": "# ğŸš§ Under Construction ğŸ—ï¸",
    "crumbs": [
      "ğŸš€ Quickstart",
      "ğŸ¤– What is an Agent?",
      "The Lasagna `Agent`"
    ]
  },
  {
    "objectID": "deployment/database.html",
    "href": "deployment/database.html",
    "title": "Database Management",
    "section": "",
    "text": "# ğŸš§ Under Construction ğŸ—ï¸",
    "crumbs": [
      "ğŸš€ Quickstart",
      "â˜ï¸ How to Deploy",
      "Database Management"
    ]
  },
  {
    "objectID": "installing.html",
    "href": "installing.html",
    "title": "ğŸ“¡ Install Lasagna AI",
    "section": "",
    "text": "Donâ€™t Install the WRONG library\n\n\n\nThe correct PyPI library is lasagna-ai (not lasagna).\n\n\npip install lasagna-ai     # &lt;-- ğŸ‰ğŸ‰ğŸ‰\n\n\nYouâ€™ll likely want some of the optional dependencies (depending on which providers you plan to use):\npip install lasagna-ai[openai,anthropic,bedrock]",
    "crumbs": [
      "ğŸš€ Quickstart",
      "ğŸ“¡ Install Lasagna AI"
    ]
  },
  {
    "objectID": "installing.html#installing",
    "href": "installing.html#installing",
    "title": "ğŸ“¡ Install Lasagna AI",
    "section": "",
    "text": "Donâ€™t Install the WRONG library\n\n\n\nThe correct PyPI library is lasagna-ai (not lasagna).\n\n\npip install lasagna-ai     # &lt;-- ğŸ‰ğŸ‰ğŸ‰\n\n\nYouâ€™ll likely want some of the optional dependencies (depending on which providers you plan to use):\npip install lasagna-ai[openai,anthropic,bedrock]",
    "crumbs": [
      "ğŸš€ Quickstart",
      "ğŸ“¡ Install Lasagna AI"
    ]
  },
  {
    "objectID": "installing.html#check-your-version",
    "href": "installing.html#check-your-version",
    "title": "ğŸ“¡ Install Lasagna AI",
    "section": "Check your version!",
    "text": "Check your version!\n\nimport lasagna\n\nprint(lasagna.__version__)\n\nâš ï¸ Make sure you have the most recent version. âš ï¸\nSee all versions on PyPI:",
    "crumbs": [
      "ğŸš€ Quickstart",
      "ğŸ“¡ Install Lasagna AI"
    ]
  },
  {
    "objectID": "agent_features/structured_output.html",
    "href": "agent_features/structured_output.html",
    "title": "Structured Output",
    "section": "",
    "text": "# ğŸš§ Under Construction ğŸ—ï¸",
    "crumbs": [
      "ğŸš€ Quickstart",
      "âš™ï¸ Agent Features",
      "Structured Output"
    ]
  },
  {
    "objectID": "agent_features/parallelizing.html",
    "href": "agent_features/parallelizing.html",
    "title": "Parallelizing",
    "section": "",
    "text": "# ğŸš§ Under Construction ğŸ—ï¸",
    "crumbs": [
      "ğŸš€ Quickstart",
      "âš™ï¸ Agent Features",
      "Parallelizing"
    ]
  },
  {
    "objectID": "recipes/committee.html",
    "href": "recipes/committee.html",
    "title": "Committee Example",
    "section": "",
    "text": "# ğŸš§ Under Construction ğŸ—ï¸",
    "crumbs": [
      "ğŸš€ Quickstart",
      "ğŸ˜‹ Recipes",
      "Committee Example"
    ]
  }
]