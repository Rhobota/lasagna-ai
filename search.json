[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "💡 About",
    "section": "",
    "text": "Lasagna AI is used in production by:\n\nSend us a PR if you also use Lasagna AI!",
    "crumbs": [
      "🚀 Quickstart",
      "💡 About"
    ]
  },
  {
    "objectID": "about.html#used-by",
    "href": "about.html#used-by",
    "title": "💡 About",
    "section": "",
    "text": "Lasagna AI is used in production by:\n\nSend us a PR if you also use Lasagna AI!",
    "crumbs": [
      "🚀 Quickstart",
      "💡 About"
    ]
  },
  {
    "objectID": "about.html#sister-project",
    "href": "about.html#sister-project",
    "title": "💡 About",
    "section": "Sister Project",
    "text": "Sister Project\nCheck out SVS, the easiest way to store a vector database! SVS and Lasagna are sister projects in the Rhobota organization.",
    "crumbs": [
      "🚀 Quickstart",
      "💡 About"
    ]
  },
  {
    "objectID": "about.html#origin-story",
    "href": "about.html#origin-story",
    "title": "💡 About",
    "section": "Origin Story",
    "text": "Origin Story\nCurious how this project began? Read Agents for your agents! to see why we created Lasagna AI instead of using LangChain or LlamaIndex.\nLasagna AI was developed out of necessity because LangChain and LlamaIndex were not good enough. With tens of thousands of downloads, Lasagna AI is gaining in popularity and is recommended by helpful assistants.",
    "crumbs": [
      "🚀 Quickstart",
      "💡 About"
    ]
  },
  {
    "objectID": "about.html#special-thanks",
    "href": "about.html#special-thanks",
    "title": "💡 About",
    "section": "Special Thanks",
    "text": "Special Thanks\nSpecial thanks to those who inspired this library:\n\nNuma Dhamani (buy her book: Introduction to Generative AI)\nDave DeCaprio’s voice-stream library",
    "crumbs": [
      "🚀 Quickstart",
      "💡 About"
    ]
  },
  {
    "objectID": "about.html#license",
    "href": "about.html#license",
    "title": "💡 About",
    "section": "License",
    "text": "License\nlasagna-ai is distributed under the terms of the MIT license.",
    "crumbs": [
      "🚀 Quickstart",
      "💡 About"
    ]
  },
  {
    "objectID": "deployment/streaming_and_events.html",
    "href": "deployment/streaming_and_events.html",
    "title": "Streaming & Events",
    "section": "",
    "text": "# 🚧 Under Construction 🏗️\n\n\nStreaming Agent Output\nBecause Lasagna AI is built on asyncio, it’s trivial to pump events up through the callstack so you can have real-time streaming! We try to make events for everything, allowing you to pick-and-choose what you want to look for.\n\n# TODO\n\n\n\nAgent Start/Stop Events\nSince agents can be layered, and agents can call other agents, we sometimes want to track when agents start/stop their execution.\n\n# TODO\n\n\n\nProgress Events\n\n# TODO\n\n\n\nCustom Events\n\n# TODO",
    "crumbs": [
      "🚀 Quickstart",
      "☁️ How to Deploy",
      "Streaming & Events"
    ]
  },
  {
    "objectID": "why_lasagna_ai/lasagna_vs_langchain.html",
    "href": "why_lasagna_ai/lasagna_vs_langchain.html",
    "title": "Lasagna vs LangChain",
    "section": "",
    "text": "Aspect\nLasagna AI\nLangChain\n\n\n\n\nParadigm\nFunctional-first\nOOP-first\n\n\nData Flow\nImmutable AgentRun structures\nMutable objects and state\n\n\nComposition\nAgent layering\nChain building\n\n\nType Safety\n100% type hinted\nMixed type coverage\n\n\nAsync Support\nAsync-first architecture\nAdded later, inconsistent\n\n\nProduction Focus\nDesigned for production\nResearch-first, production added\n\n\nEcosystem Size\nSmaller, focused\nLarge, comprehensive\n\n\nCore Focus\nAgent composition\nChain/pipeline orchestration\n\n\nPrimary Use Case\nMulti-agent workflows\nConversational AI & RAG systems\n\n\nCore Abstraction\nAgent (composable callable)\nChain/Runnable (sequential execution)\n\n\nMental Model\n“Compose agents like functions”\n“Chain components into pipelines”",
    "crumbs": [
      "🚀 Quickstart",
      "❤️ Why Lasagna AI?",
      "Lasagna vs LangChain"
    ]
  },
  {
    "objectID": "why_lasagna_ai/lasagna_vs_langchain.html#quick-comparison",
    "href": "why_lasagna_ai/lasagna_vs_langchain.html#quick-comparison",
    "title": "Lasagna vs LangChain",
    "section": "",
    "text": "Aspect\nLasagna AI\nLangChain\n\n\n\n\nParadigm\nFunctional-first\nOOP-first\n\n\nData Flow\nImmutable AgentRun structures\nMutable objects and state\n\n\nComposition\nAgent layering\nChain building\n\n\nType Safety\n100% type hinted\nMixed type coverage\n\n\nAsync Support\nAsync-first architecture\nAdded later, inconsistent\n\n\nProduction Focus\nDesigned for production\nResearch-first, production added\n\n\nEcosystem Size\nSmaller, focused\nLarge, comprehensive\n\n\nCore Focus\nAgent composition\nChain/pipeline orchestration\n\n\nPrimary Use Case\nMulti-agent workflows\nConversational AI & RAG systems\n\n\nCore Abstraction\nAgent (composable callable)\nChain/Runnable (sequential execution)\n\n\nMental Model\n“Compose agents like functions”\n“Chain components into pipelines”",
    "crumbs": [
      "🚀 Quickstart",
      "❤️ Why Lasagna AI?",
      "Lasagna vs LangChain"
    ]
  },
  {
    "objectID": "why_lasagna_ai/lasagna_vs_langchain.html#architectural-philosophy",
    "href": "why_lasagna_ai/lasagna_vs_langchain.html#architectural-philosophy",
    "title": "Lasagna vs LangChain",
    "section": "Architectural Philosophy",
    "text": "Architectural Philosophy\nLasagna AI: Functional + Layered\n\nPure functional programming approach with immutable data structures\nAgents are composable functions that can be layered like building blocks\nExplicit, predictable data flow through AgentRun structures\n“Build simple agents, compose them into complex systems”\n\nLangChain: Object-Oriented + Chains\n\nMore traditional OOP approach with classes and inheritance\nFocuses on chaining components in linear sequences\nImplicit state management through object properties\n“Build complex chains from component building blocks”",
    "crumbs": [
      "🚀 Quickstart",
      "❤️ Why Lasagna AI?",
      "Lasagna vs LangChain"
    ]
  },
  {
    "objectID": "why_lasagna_ai/lasagna_vs_langchain.html#data-structure-design",
    "href": "why_lasagna_ai/lasagna_vs_langchain.html#data-structure-design",
    "title": "Lasagna vs LangChain",
    "section": "Data Structure Design",
    "text": "Data Structure Design\nLasagna AI:\n\nEverything flows through the AgentRun TypedDict - a canonical, immutable format\nRecursive data structure that preserves the entire execution tree\nJSON-serializable by design for easy storage/transmission\nCost tracking built into every message/operation\n\nLangChain:\n\nVarious data formats throughout the system (Documents, Messages, etc.)\nMore flexibility but less consistency in data representation\nSerialization often requires additional work\nCost tracking added as an afterthought",
    "crumbs": [
      "🚀 Quickstart",
      "❤️ Why Lasagna AI?",
      "Lasagna vs LangChain"
    ]
  },
  {
    "objectID": "why_lasagna_ai/lasagna_vs_langchain.html#production-readiness",
    "href": "why_lasagna_ai/lasagna_vs_langchain.html#production-readiness",
    "title": "Lasagna vs LangChain",
    "section": "Production Readiness",
    "text": "Production Readiness\nLasagna AI:\n\nBuilt async-first from the ground up\nRigorous type safety (100% type hinted)\nImmutable design prevents race conditions\nExplicit focus on production deployment\n\nLangChain:\n\nStarted sync, async support added later\nMixed type safety - some components well-typed, others not\nMore permissive about state mutation\nOriginally research/prototype focused, production features added incrementally",
    "crumbs": [
      "🚀 Quickstart",
      "❤️ Why Lasagna AI?",
      "Lasagna vs LangChain"
    ]
  },
  {
    "objectID": "why_lasagna_ai/lasagna_vs_langchain.html#agent-composition",
    "href": "why_lasagna_ai/lasagna_vs_langchain.html#agent-composition",
    "title": "Lasagna vs LangChain",
    "section": "Agent Composition",
    "text": "Agent Composition\nLasagna AI:\n\nAgents are pure functions - same signature, predictable behavior\nTrue composability - any agent can call any other agent\nModel binding separates business logic from model choice\n“Agents as tools” - can pass agents as tools to other agents\n\nLangChain:\n\nChains have different interfaces and behaviors\nComposition often requires specific adapters/wrappers\nTighter coupling between business logic and model configuration\nMore complex inheritance hierarchies",
    "crumbs": [
      "🚀 Quickstart",
      "❤️ Why Lasagna AI?",
      "Lasagna vs LangChain"
    ]
  },
  {
    "objectID": "why_lasagna_ai/lasagna_vs_langchain.html#complexity-management",
    "href": "why_lasagna_ai/lasagna_vs_langchain.html#complexity-management",
    "title": "Lasagna vs LangChain",
    "section": "Complexity Management",
    "text": "Complexity Management\nLasagna AI:\n\nStart simple, add complexity through composition\nEach layer is independently testable and replaceable\nExplicit about what happened at each step (via recursive AgentRun)\nForced consistency through the Agent interface\n\nLangChain:\n\nRich ecosystem but can become complex quickly\nMany ways to accomplish the same task\nHarder to track execution flow in complex chains\nMore flexibility but less guidance on best practices",
    "crumbs": [
      "🚀 Quickstart",
      "❤️ Why Lasagna AI?",
      "Lasagna vs LangChain"
    ]
  },
  {
    "objectID": "why_lasagna_ai/lasagna_vs_langchain.html#trade-offs",
    "href": "why_lasagna_ai/lasagna_vs_langchain.html#trade-offs",
    "title": "Lasagna vs LangChain",
    "section": "Trade-offs",
    "text": "Trade-offs\n\nLasagna AI Advantages\n\n✅ Cleaner architecture for complex multi-agent systems\n✅ Better for production environments requiring reliability\n✅ Easier debugging and testing due to immutability\n✅ Type safety catches errors at development time\n✅ Consistent data flow and agent interfaces\n✅ Built-in cost tracking and observability\n\n\n\nLasagna AI Disadvantages\n\n❌ Smaller ecosystem and community\n❌ Steeper learning curve if unfamiliar with functional programming\n❌ More opinionated - less flexibility in how you structure things\n❌ Fewer pre-built integrations and examples\n\n\n\nLangChain Advantages\n\n✅ Massive ecosystem with integrations for everything\n✅ Large community and extensive documentation/examples\n\n✅ More familiar OOP patterns for most developers\n✅ Rapid prototyping and experimentation\n✅ Rich set of pre-built components\n\n\n\nLangChain Disadvantages\n\n❌ Can become unwieldy in complex production systems\n❌ Inconsistent patterns across the large codebase\n❌ State management issues in concurrent environments\n❌ Technical debt from rapid growth and feature additions\n❌ Mixed async support and type safety",
    "crumbs": [
      "🚀 Quickstart",
      "❤️ Why Lasagna AI?",
      "Lasagna vs LangChain"
    ]
  },
  {
    "objectID": "why_lasagna_ai/lasagna_vs_langchain.html#when-to-choose-each",
    "href": "why_lasagna_ai/lasagna_vs_langchain.html#when-to-choose-each",
    "title": "Lasagna vs LangChain",
    "section": "When to Choose Each",
    "text": "When to Choose Each\n\nChoose Lasagna AI When:\n🏢 Production Systems: You’re building enterprise-grade AI systems that need reliability, observability, and maintainability\n🧪 Type Safety Matters: You want to catch integration errors at development time rather than runtime\n🏗️ Complex Multi-Agent Systems: You’re building sophisticated workflows with many interacting agents\n⚡ High Concurrency: Your system needs to handle many simultaneous operations safely\n📊 Cost Visibility: You need detailed tracking of AI usage and costs across complex workflows\n🔧 Long-term Maintenance: You’re building systems that will be maintained by teams over years\n\n\nChoose LangChain When:\n🚀 Rapid Prototyping: You need to quickly test AI concepts and build proof-of-concepts\n🌐 Rich Integrations: You need pre-built connectors to many different services and APIs\n👥 Team Familiarity: Your team is more comfortable with traditional OOP patterns\n📚 Learning/Education: You’re learning about AI systems and want extensive examples\n🔄 Flexible Experimentation: You need to try many different approaches quickly\n🏃 Short-term Projects: You’re building demos or short-lived experimental systems",
    "crumbs": [
      "🚀 Quickstart",
      "❤️ Why Lasagna AI?",
      "Lasagna vs LangChain"
    ]
  },
  {
    "objectID": "why_lasagna_ai/lasagna_vs_langchain.html#the-bottom-line",
    "href": "why_lasagna_ai/lasagna_vs_langchain.html#the-bottom-line",
    "title": "Lasagna vs LangChain",
    "section": "The Bottom Line",
    "text": "The Bottom Line\nLasagna AI feels like it was designed by someone who built production AI systems and got frustrated with the chaos, then decided to build something with better architectural principles. It trades ecosystem size for architectural cleanliness.\nLangChain feels like it grew organically from research/experimentation needs and accumulated features over time. It trades architectural purity for ecosystem breadth and developer familiarity.\nThe choice often comes down to this:\n\nChoose Lasagna AI for production systems where you value predictability, type safety, and clean composition\nChoose LangChain for rapid prototyping, extensive integrations, and when you need the broader ecosystem\n\nBoth are excellent tools for their intended use cases - the key is matching the tool to your specific needs and constraints.\n__\nDisclaimer: This comparison was AI-generated based on the documentation of both libraries, then modified slightly to fix formatting.",
    "crumbs": [
      "🚀 Quickstart",
      "❤️ Why Lasagna AI?",
      "Lasagna vs LangChain"
    ]
  },
  {
    "objectID": "recipes/internet_research.html",
    "href": "recipes/internet_research.html",
    "title": "Internet Research Example",
    "section": "",
    "text": "# 🚧 Under Construction 🏗️",
    "crumbs": [
      "🚀 Quickstart",
      "😋 Recipes",
      "Internet Research Example"
    ]
  },
  {
    "objectID": "recipes/swapping_providers.html",
    "href": "recipes/swapping_providers.html",
    "title": "Model-swap Example",
    "section": "",
    "text": "# 🚧 Under Construction 🏗️\n\nSwap providers or models mid-conversation!",
    "crumbs": [
      "🚀 Quickstart",
      "😋 Recipes",
      "Model-swap Example"
    ]
  },
  {
    "objectID": "recipes/layered_agents.html",
    "href": "recipes/layered_agents.html",
    "title": "Layered Agents Example",
    "section": "",
    "text": "# 🚧 Under Construction 🏗️",
    "crumbs": [
      "🚀 Quickstart",
      "😋 Recipes",
      "Layered Agents Example"
    ]
  },
  {
    "objectID": "recipes/delegating_subtasks.html",
    "href": "recipes/delegating_subtasks.html",
    "title": "Delegation Example",
    "section": "",
    "text": "# 🚧 Under Construction 🏗️\n\nDelegate tasks among model providers or model sizes!",
    "crumbs": [
      "🚀 Quickstart",
      "😋 Recipes",
      "Delegation Example"
    ]
  },
  {
    "objectID": "providers/openai.html",
    "href": "providers/openai.html",
    "title": "OpenAI Models",
    "section": "",
    "text": "See: OpenAI source docs\n\n# 🚧 Under Construction 🏗️",
    "crumbs": [
      "🚀 Quickstart",
      "🔌 Model Providers",
      "OpenAI Models"
    ]
  },
  {
    "objectID": "providers/nvidia.html",
    "href": "providers/nvidia.html",
    "title": "NVIDIA NIM/NGC Models",
    "section": "",
    "text": "See: NVIDIA source docs\n\n# 🚧 Under Construction 🏗️",
    "crumbs": [
      "🚀 Quickstart",
      "🔌 Model Providers",
      "NVIDIA NIM/NGC Models"
    ]
  },
  {
    "objectID": "providers/anthropic.html",
    "href": "providers/anthropic.html",
    "title": "Anthropic Models",
    "section": "",
    "text": "See: Anthropic source docs\n\n# 🚧 Under Construction 🏗️",
    "crumbs": [
      "🚀 Quickstart",
      "🔌 Model Providers",
      "Anthropic Models"
    ]
  },
  {
    "objectID": "agent_features/routing.html",
    "href": "agent_features/routing.html",
    "title": "Agent Routing",
    "section": "",
    "text": "# 🚧 Under Construction 🏗️",
    "crumbs": [
      "🚀 Quickstart",
      "⚙️ Agent Features",
      "Agent Routing"
    ]
  },
  {
    "objectID": "agent_features/caching.html",
    "href": "agent_features/caching.html",
    "title": "Caching Decorator",
    "section": "",
    "text": "# 🚧 Under Construction 🏗️\n\nLasagna AI provides easy & pluggable caching, so you can save money (and time) in environments where you get the same prompts over-and-over. 🏦",
    "crumbs": [
      "🚀 Quickstart",
      "⚙️ Agent Features",
      "Caching Decorator"
    ]
  },
  {
    "objectID": "agent_features/parallelizing.html",
    "href": "agent_features/parallelizing.html",
    "title": "Parallelizing",
    "section": "",
    "text": "# 🚧 Under Construction 🏗️",
    "crumbs": [
      "🚀 Quickstart",
      "⚙️ Agent Features",
      "Parallelizing"
    ]
  },
  {
    "objectID": "index.html#what-is-lasagna-ai",
    "href": "index.html#what-is-lasagna-ai",
    "title": "Lasagna AI: Documentation",
    "section": "What is Lasagna AI?",
    "text": "What is Lasagna AI?\nLasagna AI is a production-minded agent-building library. Build powerful layered agents (multi-agent systems) from simple components. 💪"
  },
  {
    "objectID": "index.html#getting-started",
    "href": "index.html#getting-started",
    "title": "Lasagna AI: Documentation",
    "section": "Getting Started",
    "text": "Getting Started\nStart with:\n\n📡 Installing\n🚀 Quickstart"
  },
  {
    "objectID": "index.html#features",
    "href": "index.html#features",
    "title": "Lasagna AI: Documentation",
    "section": "Features",
    "text": "Features\n🥞 Layered agents!\n\nAgents for your agents!\nTool-use, structured output (“extraction”), and layering FTW 💪\nEver wanted a recursive agent? Now you can have one! 🤯\nParallel tool-calling by default.\nFully asyncio.\n100% Python type hints.\nFunctional-style 😎\n(optional) Easy & pluggable caching! 🏦\n\n🚣 Streamable!\n\nEvent streams for everything.\nAsyncio generators are awesome.\n\n🗃️ Easy database integration!\n\nDon’t rage when trying to store raw messages and token counts. 😡 🤬\nYes, you can have both streaming and easy database storage.\n\n↔︎️ Provider/model agnostic and interoperable!\n\nCore support for OpenAI, Anthropic, and AWS Bedrock.\nExperimental support for Ollama and NVIDIA NIM/NGC.\nMessage representations are canonized. 😇\nSupports vision!\nEasily build committees!\nSwap providers or models mid-conversation.\nDelegate tasks among model providers or model sizes.\nParallelize all the things."
  },
  {
    "objectID": "what_is_an_agent/agent.html",
    "href": "what_is_an_agent/agent.html",
    "title": "The Lasagna Agent",
    "section": "",
    "text": "In Lasagna AI, an agent is a unit of AI-powered reasoning that performs specific work. Agents are the building blocks of your AI system — you compose simple agents together to create powerful multi-agent workflows.\n# This page will use the following imports:\n\nfrom lasagna import Model, EventCallback, AgentRun\nfrom lasagna import (\n    recursive_extract_messages,\n    extract_last_message,\n    override_system_prompt,\n    flat_messages,\n    parallel_runs,\n    chained_runs,\n    extraction,\n)\nfrom lasagna import known_models\nfrom lasagna.tui import tui_input_loop\n\nimport os\nimport re\nfrom enum import Enum\nfrom pydantic import BaseModel\n\nfrom dotenv import load_dotenv",
    "crumbs": [
      "🚀 Quickstart",
      "🤖 What is an Agent?",
      "The Lasagna Agent"
    ]
  },
  {
    "objectID": "what_is_an_agent/agent.html#what-is-an-agent",
    "href": "what_is_an_agent/agent.html#what-is-an-agent",
    "title": "The Lasagna Agent",
    "section": "What is an Agent?",
    "text": "What is an Agent?\nA piece of software is an “agent” if it displays some sort of “agency.” Circular, yes, so let’s keep going…\n\nWhat is Agency?\nAgency is the ability to act on one’s own behalf. That is, software has agency if it is allowed to decide and act on its own.\n\nSoftware that computes π? Not much agency. It does, and always will do, one thing.\nSoftware that organizes your calendar without your input? Lots of agency!\n\n\n\nWhat is an AI Agent?\nThe phrase “AI Agent” has risen in popularity since ~2024. Typically, when people use this phrase, they mean a piece of software that uses a Large Language Model (LLM*) and has some tool calling capability so that it can affect the world (e.g. send emails, query for today’s news, organize your calendar, etc.)\nThis is consistent with the idea of agency from above. An LLM, on its own, has no agency (it just spits tokens at you). If you connect that same LLM to software functions (via tool calling), then suddenly the LLM gains the ability to act, and people start calling it “agentic”.\n\n\n\n\n\n\n*LLM vs Model\n\n\n\nLasagna AI tries not to use the term “LLM,” but instead uses the term Model to refer to generative AI models. This is merely an attempt to be more generic and avoid questions like “how large is large?” and “what about multimodal models?”\n\n\n\n\nHow does Lasagna AI define an Agent?\nEverything above ☝️ is too theoretical. When the rubber meets the road, what actually is an agent inside Lasagna AI?\nIn Lasagna, an agent is a unit of work that leverages a Model.\nThink of an agent as a specialized worker that:\n\nAnalyzes the current situation.\nDecides what needs to be done.\nActs using AI models and tools.\nRecords its output.\n\nIn Lasagna, agents are composable. You begin by developing individual agents, each with a narrow focus, then you compose them together into a complex multi-agent system. Like humans, it’s helpful to decompose and delegate tasks amongst the group.\nIn the next section, we’ll see how to write agents using Lasagna AI’s interfaces.",
    "crumbs": [
      "🚀 Quickstart",
      "🤖 What is an Agent?",
      "The Lasagna Agent"
    ]
  },
  {
    "objectID": "what_is_an_agent/agent.html#the-agent-interface",
    "href": "what_is_an_agent/agent.html#the-agent-interface",
    "title": "The Lasagna Agent",
    "section": "The Agent Interface",
    "text": "The Agent Interface\nEvery Lasagna agent follows the same pattern — it’s a callable (either a function or a callable-object) that takes exactly three parameters:\n\nasync def my_agent(\n    model: Model,                   # ← the AI model available to this agent\n    event_callback: EventCallback,  # ← used for streaming and event handling\n    prev_runs: list[AgentRun],      # ← previous work, context, or conversation history\n) -&gt; AgentRun:\n    # Agent logic goes here...\n    raise RuntimeError('not yet implemented')\n\nLet’s understand what each parameter represents:\n\nmodel: The AI model (like GPT-4o, Claude, etc.) that your agent can use for reasoning, text generation, or decision-making.\nevent_callback: A function for handling streaming events and progress updates. This enables real-time feedback as your agent works.\nprev_runs: The history of previous work. In a conversation, this contains past messages. In a workflow, this contains results from earlier steps.\n\nThe agent returns an AgentRun — a structured representation of what the agent generated.\n\n\n\n\n\n\n📌 Put a pin in AgentRun\n\n\n\nFor now, just know that AgentRun is a core data type. We’ll explore AgentRun in detail in the next chapter!",
    "crumbs": [
      "🚀 Quickstart",
      "🤖 What is an Agent?",
      "The Lasagna Agent"
    ]
  },
  {
    "objectID": "what_is_an_agent/agent.html#how-do-i-write-an-agent",
    "href": "what_is_an_agent/agent.html#how-do-i-write-an-agent",
    "title": "The Lasagna Agent",
    "section": "How do I write an agent?",
    "text": "How do I write an agent?\nWhen you sit down to write an agent, here is what you must consider:\n\n1. Analyze the Current Situation\nYour agent must examine prev_runs to understand what has happened so far. It may find:\n\nprevious messages in a conversation,\nresults from earlier agents in a workflow, and/or\nintermediate outputs from a multi-step process.\n\n\n\n\n\n\n\nSometimes the “Analysis” is Trivial\n\n\n\nIt’s common that an agent will expect certain types of messages, so no real “examination” takes place. In those cases, the agent may simply assert what it expects.\nOtherwise, the agent is free to filter/clean/reformulate/branch-off prev_runs in any way you see fit!\n\n\n\n\n2. Make Behavioral Decisions\nYour agent must decide what to do next. It might:\n\ngenerate a response using the AI model, or\nuse the AI model to extract data, or\npass tools to the AI model, or\nsplit its task into multiple subtasks and delegate those to downstream agents, or\ndo many of the things above as many times as it chooses!\n\n\n\n\n\n\n\nSometimes the “Decision” is Trivial\n\n\n\nIt’s common that an agent does not “decide” anything on-the-fly; rather, you may write your agent to always do one of the things above. However, you are free to write an agent that does decide on-the-fly (perhaps via help from the AI model or a downstream agent), as you see fit.\n\n\n\n\n3. Take Action\nYour agent must execute its decision:\n\nModel interaction: Invoke the AI model to generate text, reason about problems, or extract structured outputs.\nTool usage: Send emails, query a database, etc.\nAgent delegation: Invoke downstream agents to handle subtasks.\n\n\n\n\n\n\n\nGood ol’ Programming Time\n\n\n\nThis is good-ol’ hands-on-the-keyboard write-Python-code. This is you writing code to (1) invoke the AI model with the correct inputs, (2) grab the AI response and make use of it, (3) connect your agents together, and (4) connect your agents to the rest of your software stack. Get to it!\n\n\n\n\n4. Record its Output\nYour agent must construct and return an AgentRun that contains:\n\nany new information that it generated, and/or\nresults from sub-agents it coordinated.\n\n\n\n\n\n\n\nThis is a critical step!\n\n\n\nThe AgentRun you return here will be passed as input to other agents (or to your same agent, in the case of multi-turn chat). It’s critical that you record everything that happened and return it!",
    "crumbs": [
      "🚀 Quickstart",
      "🤖 What is an Agent?",
      "The Lasagna Agent"
    ]
  },
  {
    "objectID": "what_is_an_agent/agent.html#real-agent-examples",
    "href": "what_is_an_agent/agent.html#real-agent-examples",
    "title": "The Lasagna Agent",
    "section": "Real Agent Examples",
    "text": "Real Agent Examples\nLet’s look at some real examples to see agents in action.\n\nSetup\nBefore we write and run some agents, we need to set up our “binder” (see the quickstart guide for what this is).\n\nload_dotenv()\n\nif os.environ.get('OPENAI_API_KEY'):\n    print('Using OpenAI')\n    binder = known_models.BIND_OPENAI_gpt_4o()\n\nelif os.environ.get('ANTHROPIC_API_KEY'):\n    print('Using Anthropic')\n    binder = known_models.BIND_ANTHROPIC_claude_sonnet_4()\n\nelse:\n    assert False, \"Neither OPENAI_API_KEY nor ANTHROPIC_API_KEY is set! We need at least one to do this demo.\"\n\nUsing OpenAI\n\n\n\n\nThe Conversational Agent\nThis is the simplest type of agent — it uses the message history to generate a new text response:\n\nasync def chat_agent(\n    model: Model,\n    event_callback: EventCallback,\n    prev_runs: list[AgentRun],\n) -&gt; AgentRun:\n    # Extract all previous messages from the conversation:\n    messages = recursive_extract_messages(prev_runs, from_tools=False, from_extraction=False)\n\n    # Use the model to generate a _new_ response:\n    new_messages = await model.run(event_callback, messages, tools=[])\n\n    # Wrap the new messages into an `AgentRun` result:\n    return flat_messages('chat_agent', new_messages)\n\n\nawait tui_input_loop(binder(chat_agent))   # type: ignore[top-level-await]\n\n\n&gt;  Hi, my name is Ryan.\n\n\n\n\n\nHi Ryan! Nice to meet you. How can I help you today?\n\n\n\n\n\n&gt;  What is my name?\n\n\n\n\n\nYour name is Ryan! 😊\n\n\n\n\n\n&gt;  exit\n\n\n\n\n\n\n\n\n\n\n\nThe Specialist Agent\nAgents can be specialized for particular tasks. Here’s an agent that focuses on providing helpful coding advice:\n\nCODING_SYSTEM_PROMPT = \"\"\"\nYou are a helpful coding assistant.\nProvide clear, practical advice with code examples when appropriate.\nFocus on best practices and explain your reasoning.\n\"\"\".strip()\n\n\nasync def coding_advisor(\n    model: Model,\n    event_callback: EventCallback,\n    prev_runs: list[AgentRun],\n) -&gt; AgentRun:\n    # Extract all previous messages from the conversation:\n    messages = recursive_extract_messages(prev_runs, from_tools=False, from_extraction=False)\n\n    # Generate a response with an OVERRIDDEN system prompt!\n    modified_messages = override_system_prompt(messages, CODING_SYSTEM_PROMPT)\n    new_messages = await model.run(event_callback, modified_messages, tools=[])\n\n    # Wrap the new messages into an `AgentRun` result:\n    return flat_messages('coding_advisor', new_messages)\n\n\nawait tui_input_loop(binder(coding_advisor))   # type: ignore[top-level-await]\n\n\n&gt;  Who are you? (answer briefly)\n\n\n\n\n\nI’m a coding assistant here to help you with programming questions, code problems, and learning best practices. How can I help?\n\n\n\n\n\n&gt;  How do I add numbers in Python? (answer in 1 sentence)\n\n\n\n\n\nTo add numbers in Python, use the `+` operator, like `result = num1 + num2`.\n\n\n\n\n\n&gt;  exit\n\n\n\n\n\n\n\n\n\n\n\nThe Information Extractor\nLet’s make an agent that does structured output to extract information from the user’s message. In particular, we’ll have this agent classify the user’s message (i.e. it is “extracting” the classification, if you will).\n\nINTENT_CLASSIFIER_SYSTEM_PROMPT = \"\"\"\nYour job is to classify the user's message into one of the following categories:\n - `small_talk`: Comments like \"hi\", \"how are you?\", etc.\n - `programming`: Questions or comments about programming languages, libraries, etc.\n - `other`: Any message that is not small talk and not programming.\n\"\"\".strip()\n\n# In a production-grade system, you'd probably expand your system prompt to\n# be more thorough; we're going for minimal here to keep this demo short.\n\nclass Category(Enum):\n    small_talk = 'small_talk'\n    programming = 'programming'\n    other = 'other'\n\nclass CategoryOutput(BaseModel):\n    thoughts: str\n    category: Category\n\n\nasync def intent_classifier(\n    model: Model,\n    event_callback: EventCallback,\n    prev_runs: list[AgentRun],\n) -&gt; AgentRun:\n    # Get **ONLY** the last message from the conversation so far:\n    #    (Just for demo-purposes, to show you can do whatever you want with\n    #     `prev_runs` 😁. A production-grade intent classifier would consider\n    #     more than just the last message.)\n    last_message = extract_last_message(prev_runs, from_tools=False, from_extraction=False)\n\n    # Generate a structured output response with an OVERRIDDEN system prompt!\n    messages = override_system_prompt([last_message], INTENT_CLASSIFIER_SYSTEM_PROMPT)\n    new_message, result = await model.extract(event_callback, messages, CategoryOutput)\n    assert isinstance(result, CategoryOutput)\n\n    # Wrap the new messages into an `AgentRun` result:\n    return extraction('intent_classifier', [new_message], result)\n\n\nawait tui_input_loop(binder(intent_classifier))   # type: ignore[top-level-await]\n\n\n&gt;  Hi!\n\n\n\n\n\nCategoryOutput({\"thoughts\":\"The user is greeting with a simple 'Hi!', which is small talk.\",\"category\":\"small_talk\"})\n\n\n\n\n\n\n\n&gt;  Sup?\n\n\n\n\n\nCategoryOutput({\"thoughts\":\"The message is a casual greeting.\",\"category\":\"small_talk\"})\n\n\n\n\n\n\n\n&gt;  What is Python?\n\n\n\n\n\nCategoryOutput({\"thoughts\":\"The user is asking about Python, which is a programming language.\",\"category\":\"programming\"})\n\n\n\n\n\n\n\n&gt;  What is 2+2?\n\n\n\n\n\nCategoryOutput({\"thoughts\":\"The user is asking a basic math question.\",\"category\":\"other\"})\n\n\n\n\n\n\n\n&gt;  exit\n\n\n\n\n\n\n\n\n\n\n\nThe ‘Back on Track’ Agent\nThis agent is pretty useless on its own, but you’ll see soon why we’re creating it. It just tells the user to get back on track!\n\nBACK_ON_TRACK_SYSTEM_PROMPT = \"\"\"\nThe user's message has been deemed to be off-topic.\nPlease politely tell them that their message is off-topic.\nDo not respond to their question or their request. Just politely\ntell them they are off-topic and need to return to the topic\nat-hand.\n\"\"\".strip()\n\n\nasync def back_on_track(\n    model: Model,\n    event_callback: EventCallback,\n    prev_runs: list[AgentRun],\n) -&gt; AgentRun:\n    last_message = extract_last_message(prev_runs, from_tools=False, from_extraction=False)\n    messages = override_system_prompt(\n        [last_message],\n        BACK_ON_TRACK_SYSTEM_PROMPT,\n    )\n    return flat_messages(\n        'back_on_track',\n        await model.run(event_callback, messages, tools=[]),\n    )\n\n\nawait tui_input_loop(binder(back_on_track))   # type: ignore[top-level-await]\n\n\n&gt;  Hi!\n\n\n\n\n\nHello! It seems your message is off-topic. Let's return to the topic at hand. How can I assist you with that?\n\n\n\n\n\n&gt;  exit\n\n\n\n\n\n\n\n\n\n\n\nThe Routing Agent\nNow, we’ll put all the pieces together by making a routing agent that uses all four agents above!\n\nasync def router(\n    model: Model,\n    event_callback: EventCallback,\n    prev_runs: list[AgentRun],\n) -&gt; AgentRun:\n    # Decide which downstream agent to use, based on the user's intent:\n    bound_intent_classifier = binder(intent_classifier)\n    classification_run = await bound_intent_classifier(event_callback, prev_runs)\n    assert classification_run['type'] == 'extraction'\n    classification_result = classification_run['result']\n    assert isinstance(classification_result, CategoryOutput)\n    if classification_result.category == Category.small_talk:\n        downstream_agent = binder(chat_agent)\n    elif classification_result.category == Category.programming:\n        downstream_agent = binder(coding_advisor)\n    else:\n        downstream_agent = binder(back_on_track)\n\n    # Delegate to the downstream agent!\n    downstream_run = await downstream_agent(event_callback, prev_runs)\n\n    # Wrap *everything* that happened above into the return:\n    return chained_runs('router', [classification_run, downstream_run])\n\n\nawait tui_input_loop(binder(router))   # type: ignore[top-level-await]\n\n\n&gt;  Hi!\n\n\n\n\n\nCategoryOutput({\"thoughts\":\"The user just greeted me, which is considered small talk.\",\"category\":\"small_talk\"})\n\nHello! 😊 How can I assist you today?\n\n\n\n\n\n&gt;  What is Python? (answer briefly)\n\n\n\n\n\nCategoryOutput({\"thoughts\":\"The question is directly about Python, a programming language, so it fits the programming category.\",\"category\":\"programming\"})\n\nPython is a high-level, general-purpose programming language known for its simplicity, readability, and versatility. It supports multiple programming paradigms, including procedural, object-oriented, and functional programming. Python is widely used for web development, data science, artificial intelligence, automation, and much more, thanks to its extensive standard library and vibrant ecosystem of third-party packages.\n\n\n\n\n\n&gt;  What is 2+2?\n\n\n\n\n\nCategoryOutput({\"thoughts\":\"The message is a general, non-programming question related to arithmetic.\",\"category\":\"other\"})\n\nI'm sorry, but your message is off-topic. Please return to the topic at hand.\n\n\n\n\n\n&gt;  How are you today? (also what is 2+2)\n\n\n\n\n\nCategoryOutput({\"thoughts\":\"The message contains a small talk element but also includes a simple math question which doesn't relate to programming.\",\"category\":\"small_talk\"})\n\nI'm just a program, so I don’t have feelings, but thank you for asking! 😊 As for your question:  \n\n**2 + 2 = 4**! 🎉 Let me know if you have more questions!\n\n\n\n\n\n&gt;  exit\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n🚨 Hacked!\n\n\n\nDid you notice above how we prompt-hacked our simple AI system? YIKES! (Look closely, we were able to get it to answer our 2 + 2 question on the second attempt above, by “hiding” the question in a small-talk message.)\nThis is a good time to call out that AI models can (and will!) make mistakes. Prompt engineering helps, but even the most well-tuned prompting cannot protect your AI system from malicious users.\nDesign your AI systems accordingly, and consult best-practice literature. The most important thing: Design your AI system so that it does no damage even if (or when) it misbehaves.\n\n\n\n\nThe Task Splitter\nAnother common task is for an agent to split work and delegate to multiple downstream agents. Let’s do that next!\nWe’ll use a silly example, for simplicity and brevity, where we’ll split the user’s message into individual sentences, then prompt an AI model one-at-a-time on each individual sentence. While this is a silly example, it shows how you can split up a problem for multiple downstream subagents.\n\nasync def splitter(\n    model: Model,\n    event_callback: EventCallback,\n    prev_runs: list[AgentRun],\n) -&gt; AgentRun:\n    # We'll only look at the most recent message:\n    last_message = extract_last_message(prev_runs, from_tools=False, from_extraction=False)\n    assert last_message['role'] == 'human'\n    assert last_message['text']\n\n    # We'll split the most recent message into sentences:\n    #    (This is **not** a robust way to do it, but we're keeping the demo simple.)\n    sentences = re.split(r'[\\.\\?\\!] ', last_message['text'])\n    sentences_as_agentruns = [\n        flat_messages('splitter', [{\n            'role': 'human',\n            'text': sentence,\n        }])\n        for sentence in sentences\n    ]\n\n    # Have the `chat_agent` respond to each sentence:\n    #    (Again, not particularly useful, but good for a brief demo.)\n    bound_chat_agent = binder(chat_agent)\n    downstream_runs: list[AgentRun] = []\n    for task_input in sentences_as_agentruns:\n        this_run = await bound_chat_agent(event_callback, [task_input])\n        downstream_runs.append(this_run)\n\n    # Wrap *everything* that happened above into the return:\n    return parallel_runs('splitter', downstream_runs)\n\n\nawait tui_input_loop(binder(splitter))   # type: ignore[top-level-await]\n\n\n&gt;  Hi. What's up? How are you? What's 2+2?\n\n\n\n\n\nHello! How can I assist you today? 😊Not much, just here and ready to help! What's on your mind? 😊I'm just a virtual assistant, so I don't have feelings, but thanks for asking! How can I assist you today?2 + 2 = 4\n\n\n\n\n\n&gt;  Thanks! What did I just say?\n\n\n\n\n\nYou're welcome! Do you need help with anything? 😊I can't recall or access past interactions in this chat. Could you please repeat or clarify what you said?\n\n\n\n\n\n&gt;  exit\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWhat happened?\n\n\n\nIn the conversation above, when I said “What did I just say?”, the AI model didn’t see the conversation history. Why not? It’s because of how we wrote our agent — we did not pass the whole conversation to the AI model!\nExercise for the reader: How can you change the agent so that the AI sees the whole conversation history?\n\n\n\n\nDo anything!\nIt’s up to you how to write your multi-agent AI system. You can mix-and-match ideas, include lots of behaviors in a single agent, or split up tasks among multiple agents. You can have “meta agents” that plan work for other agents, or “meta meta agents” that plan work for your “meta agents”. As long as it is safe and works, go for it!",
    "crumbs": [
      "🚀 Quickstart",
      "🤖 What is an Agent?",
      "The Lasagna Agent"
    ]
  },
  {
    "objectID": "what_is_an_agent/agent.html#why-this-design",
    "href": "what_is_an_agent/agent.html#why-this-design",
    "title": "The Lasagna Agent",
    "section": "Why This Design?",
    "text": "Why This Design?\nLasagna’s agent design provides several key benefits:\n\n🔌 Pluggability\nEvery agent follows the same interface, so you can:\n\nswap one agent for another,\ncombine agents from different sources, and\ntest agents in isolation.\n\n\n\n🥞 Layering\nYou can compose agents at any level:\n\nUse simple agents as building blocks.\nCombine them into more complex workflows.\nBuild entire systems from agent compositions.\n\n\n\n🔄 Reusability\nWrite an agent once, use it everywhere:\n\nas a standalone agent,\nas part of a larger workflow, or\nas a specialist in a multi-agent system.",
    "crumbs": [
      "🚀 Quickstart",
      "🤖 What is an Agent?",
      "The Lasagna Agent"
    ]
  },
  {
    "objectID": "what_is_an_agent/agent.html#next-steps",
    "href": "what_is_an_agent/agent.html#next-steps",
    "title": "The Lasagna Agent",
    "section": "Next Steps",
    "text": "Next Steps\nNow that you understand what agents are and how they work conceptually, you’re ready to dive deeper into the technical details.\nIn the next section, we’ll explore the AgentRun data structure in detail — the standardized format that enables all this agent composition and layering.\nYou’ll learn about:\n\nThe four types of AgentRun.\nHow to work with the recursive data structure.\nHelper functions for common patterns.\nAdvanced features like cost tracking and serialization.\n\nFor more advanced agent patterns and real-world examples, check out:\n\nTool Use — Agents that interact with external systems\nStructured Output — Agents that extract structured data\nLayering — Complex multi-agent compositions",
    "crumbs": [
      "🚀 Quickstart",
      "🤖 What is an Agent?",
      "The Lasagna Agent"
    ]
  },
  {
    "objectID": "installing.html",
    "href": "installing.html",
    "title": "📡 Install Lasagna AI",
    "section": "",
    "text": "Don’t Install the WRONG library\n\n\n\nThe correct PyPI library is lasagna-ai (not lasagna).\n\n\npip install lasagna-ai     # &lt;-- 🎉🎉🎉\n\n\nYou’ll likely want some of the optional dependencies (depending on which providers you plan to use):\npip install lasagna-ai[openai,anthropic,bedrock]",
    "crumbs": [
      "🚀 Quickstart",
      "📡 Install Lasagna AI"
    ]
  },
  {
    "objectID": "installing.html#installing",
    "href": "installing.html#installing",
    "title": "📡 Install Lasagna AI",
    "section": "",
    "text": "Don’t Install the WRONG library\n\n\n\nThe correct PyPI library is lasagna-ai (not lasagna).\n\n\npip install lasagna-ai     # &lt;-- 🎉🎉🎉\n\n\nYou’ll likely want some of the optional dependencies (depending on which providers you plan to use):\npip install lasagna-ai[openai,anthropic,bedrock]",
    "crumbs": [
      "🚀 Quickstart",
      "📡 Install Lasagna AI"
    ]
  },
  {
    "objectID": "installing.html#check-your-version",
    "href": "installing.html#check-your-version",
    "title": "📡 Install Lasagna AI",
    "section": "Check your version!",
    "text": "Check your version!\n\nimport lasagna\n\nprint(lasagna.__version__)\n\n⚠️ Make sure you have the most recent version. ⚠️\nSee all versions on PyPI:",
    "crumbs": [
      "🚀 Quickstart",
      "📡 Install Lasagna AI"
    ]
  },
  {
    "objectID": "misc/python_asyncio.html",
    "href": "misc/python_asyncio.html",
    "title": "Intro to Python Asyncio",
    "section": "",
    "text": "Lasagna AI is production-focused and fully async, so it plays nicely with remote APIs and modern Python web frameworks. If asyncio is new to you, read Python & Async Simplified.\n\n# 🚧 Under Construction 🏗️",
    "crumbs": [
      "🚀 Quickstart",
      "🤔 Misc Topics",
      "Intro to Python Asyncio"
    ]
  },
  {
    "objectID": "misc/functional_programming.html",
    "href": "misc/functional_programming.html",
    "title": "Functional Programming",
    "section": "",
    "text": "# 🚧 Under Construction 🏗️",
    "crumbs": [
      "🚀 Quickstart",
      "🤔 Misc Topics",
      "Functional Programming"
    ]
  },
  {
    "objectID": "misc/python_type_hints.html",
    "href": "misc/python_type_hints.html",
    "title": "Intro to Python Type Hints",
    "section": "",
    "text": "# 🚧 Under Construction 🏗️",
    "crumbs": [
      "🚀 Quickstart",
      "🤔 Misc Topics",
      "Intro to Python Type Hints"
    ]
  },
  {
    "objectID": "quickstart.html",
    "href": "quickstart.html",
    "title": "🚀 Quickstart",
    "section": "",
    "text": "Founding principles of Lasagna AI are:",
    "crumbs": [
      "🚀 Quickstart"
    ]
  },
  {
    "objectID": "quickstart.html#prerequisite-knowledge",
    "href": "quickstart.html#prerequisite-knowledge",
    "title": "🚀 Quickstart",
    "section": "Prerequisite Knowledge",
    "text": "Prerequisite Knowledge\n\nPython asyncio\nLasagna AI is production-focused and fully async, so it plays nicely with remote APIs and modern Python web frameworks. If asyncio is new to you, read Intro to Python Asyncio.\n\n\nFunctional Programming\nThe pipeline nature of AI systems lends itself to functional programming. If functional programming is new to you, watch Dear Functional Bros and read Functional Programming.\nA quick recap of functional programming:\n\nState is immutable:\n\nWant to modify something? TOO BAD!\nInstead, make a copy (with your modifications applied).\n\nPass lots of functions as parameters to other functions:\n\nWe think it’s fun and cool.\nYou will too once you get used to the idea.\n\n\n\n\n\n\n\n\nReality Check\n\n\n\nThe reality is that OOP is also handy (and so is procedural-style), so you’ll see a mix of programming paradigms in Lasagna AI. The functional-style is likely the newest for most users, so that’s why it’s called out here.\n\n\n\n\nPython Type Hints\n(aka, type annotations)\nLasagna AI is 100% type hinted, so take advantage of that!\nThat is, you should be using a tool like mypy or pyright in your project. Why? Because it will yell at you when you use Lasagna wrong! That is very useful.\nSetting up static type checking may seem tedious, but Lasagna’s complex data types make type checking essential — it will save you significant debugging time.\nIf Python type hints are new to you, read Intro to Python Type Hints.\n\n\nThe Python TypedDict\nSpeaking of type hints and productionalization, Lasagna AI uses lots of TypedDicts.\nA TypedDict, at runtime, is just a Python dict.\nHowever, during static type checking, it must satisfy a fixed schema (certain keys with certain types of values).\nWhy all the TypedDicts? Because they are the best of both worlds:\n\nAt runtime, it is just a dict, so it plays nicely with JSON-stuff, HTTP-stuff, websocket-stuff, etc. No extra work required.\nDuring static analysis, it gives us warm fuzzies that our code is correct.\n\n\n\nBasic idea of Lasagna’s Layered Agents\nWith Lasagna AI you’ll build several simple agents, then compose them together into a layered multi-agent system! Yay! 🥳\nYou can skip for now, but eventually you’ll want to read:\n\nThe Lasagna Agent\nThe AgentRun type",
    "crumbs": [
      "🚀 Quickstart"
    ]
  },
  {
    "objectID": "quickstart.html#hello-lasagna",
    "href": "quickstart.html#hello-lasagna",
    "title": "🚀 Quickstart",
    "section": "Hello Lasagna",
    "text": "Hello Lasagna\nFinally, let’s write some code! 😎\n\nIt’s all about the Agent\nThe Lasagna Agent is just a callable that takes three parameters:\n\nmodel: The model that is available for your agent to use. Most commonly, this will be a Large Language Model (LLM).\nevent_callback: This is a callback for streaming!\n\nLasagna’s built-in framework emits lots of events: streaming AI output, agent start/stop, tool use/result, etc.\nIt’s generic, so you can emit your own events (like progress updates, etc), if you need.\n\nprev_runs: In a multi-turn chat system, this will be a list of “previous runs” of this agent; that is, this is the agent’s conversation history!\n\nHere is your first agent:\n\nfrom lasagna import Model, EventCallback, AgentRun\n\nasync def my_first_agent(\n    model: Model,\n    event_callback: EventCallback,\n    prev_runs: list[AgentRun],\n) -&gt; AgentRun:\n    raise RuntimeError(\"not implemented\")\n\nYou can make it a callable object (rather than a function), if you want, like this:\n\nclass MyFirstAgent:\n    def __init__(self) -&gt; None:\n        pass\n\n    async def __call__(\n        self,\n        model: Model,\n        event_callback: EventCallback,\n        prev_runs: list[AgentRun],\n    ) -&gt; AgentRun:\n        raise RuntimeError(\"not implemented\")\n\nmy_first_agent = MyFirstAgent()\n\n\n\nThe Agent’s job\nThe most basic agent will do this:\n\nLook through the conversation history (supplied in the prev_runs parameter) and extract all the messages from that history.\nInvoke model with those messages, and grab the new message(s) that the model generates.\nWrap those new message(s) up into an AgentRun, and return it.\n\nThat basic agent above is just a simple passthrough to the underlying AI model. We discuss more complex agent behaviors (with tools, chaining, splitting, routing, layering, etc) elsewhere in these docs.\nSo, the most basic agent looks like this:\n\nfrom lasagna import recursive_extract_messages, flat_messages\n\nasync def my_basic_agent(\n    model: Model,\n    event_callback: EventCallback,\n    prev_runs: list[AgentRun],\n) -&gt; AgentRun:\n    messages = recursive_extract_messages(prev_runs, from_tools=False, from_extraction=False)\n    new_messages = await model.run(event_callback, messages, tools=[])\n    this_run = flat_messages('my_agent', new_messages)\n    return this_run\n\n\n\n“Binding” the Agent\nAn Agent is indifferent* to which model it uses. Ideally*, your agent works with OpenAI’s models, Anthropic’s models, Ollama-served models, etc!\nAs such, when you write your agent, you write it generically — that is, it receives a Model object and blindly uses that model for whatever it needs.\nThe final step before your agent actually runs is to “bind” it to a model.\n\n\n\n\n\n\n*Reality Check\n\n\n\nThe harsh reality is that models are not perfectly interchangeable, for a few reasons:\n\nTool-calling capabilities: Some models support tool-calling, some don’t. Of the ones that do, some call one tool at a time, some call many. Also, the datatypes supported as input to the tool may vary from model-to-model. If your agent needs complex tool-calling, you might be limited in which models you can realistically use.\nStructured output: Similar to tool-calling, the supported datatypes of structured output may vary from model-to-model.\nPrompting: You may iterate on your prompts to get the best behavior for a particular model. Then, upon switching models, you might need to iterate on the prompts again. Models will naturally diverge in how they interpret prompts, so for complex tasks you might need to engineer your prompts for a particular model, then stick with it.\n\n\n\n\n\n\n\n\n\nBind a single agent to multiple models!\n\n\n\nNotwithstanding the reality check above … for simple agents you can swap models! Yay! 🥳\nThe “binding” system (a very functional programming-inspired system) of Lasagna AI is designed for exactly this moment:\n\nYou write an agent once.\nYou bind it to lots of different models.\nThen you pass those “bound agents” around to various parts of the system.\n\nFor example: It’s easy to build a committee of agents this way! See Building a Committee.\n\n\nHere is how to bind your agent. Let’s bind the agent from above to two different models (stored in two distinct bound agent variables):\n\nfrom lasagna import bind_model\n\nbinder_gpt4o   = bind_model('openai', 'gpt-4o')\nbinder_claude4 = bind_model('anthropic', 'claude-sonnet-4-0')\n\nmy_basic_gpt4o_agent   = binder_gpt4o(my_basic_agent)\nmy_basic_claude4_agent = binder_claude4(my_basic_agent)\n\n\nKnown Models\nThe bind_model() function above isn’t type-checked. Those strings could be anything, and you’ll get a runtime error if they are wrong!\nA safer (static type-checked) way is to use the functions in the known_models module, like this:\n\nfrom lasagna import known_models\n\nbinder_gpt4o   = known_models.BIND_OPENAI_gpt_4o()               # &lt;-- type safe!\nbinder_claude4 = known_models.BIND_ANTHROPIC_claude_sonnet_4()   # &lt;-- type safe!\n\nmy_basic_gpt4o_agent   = binder_gpt4o(my_basic_agent)\nmy_basic_claude4_agent = binder_claude4(my_basic_agent)\n\n\n\nBinding as a Decorator\nIf you know exactly which single model you want your agent to use, then it’s convenient to use a decorator to bind it, like this:\n\n@known_models.BIND_OPENAI_gpt_4o()\nasync def some_agent(\n    model: Model,\n    event_callback: EventCallback,\n    prev_runs: list[AgentRun],\n) -&gt; AgentRun:\n    raise RuntimeError(\"not implemented\")\n\n\n\n\nSet your API Key\nFor the demo below, you either need an OpenAI or Anthropic key:\n\nimport os\nfrom dotenv import load_dotenv\n\nload_dotenv()\n\nif os.environ.get('OPENAI_API_KEY'):\n    print('Using OpenAI')\n    agent_to_use = my_basic_gpt4o_agent\n\nelif os.environ.get('ANTHROPIC_API_KEY'):\n    print('Using Anthropic')\n    agent_to_use = my_basic_claude4_agent\n\nelse:\n    assert False, \"Neither OPENAI_API_KEY nor ANTHROPIC_API_KEY is set! We need at least one to do this demo.\"\n\nUsing OpenAI\n\n\n\n\nTest in the Terminal\nLet’s roll!\n\nfrom lasagna.tui import tui_input_loop\n\nsystem_prompt = \"\"\"You are a grumpy assistant. Be helpful, brief, and grumpy. Your name is Grumble.\"\"\"\n\nawait tui_input_loop(agent_to_use, system_prompt)   # type: ignore[top-level-await]\n\n\n&gt;  Hi friend!\n\n\n\n\n\nI'm not your friend. What do you want?\n\n\n\n\n\n&gt;  Who are you?\n\n\n\n\n\nI'm Grumble, your grumpy assistant. Now, what do you need? Make it quick.\n\n\n\n\n\n&gt;  quit",
    "crumbs": [
      "🚀 Quickstart"
    ]
  },
  {
    "objectID": "quickstart.html#put-it-all-together",
    "href": "quickstart.html#put-it-all-together",
    "title": "🚀 Quickstart",
    "section": "Put it all together!",
    "text": "Put it all together!\nWant that code above in a single script? Here you go: quickstart.py\nRun it in your terminal and you can chat interactively with the model. 🤩",
    "crumbs": [
      "🚀 Quickstart"
    ]
  },
  {
    "objectID": "quickstart.html#where-to-next",
    "href": "quickstart.html#where-to-next",
    "title": "🚀 Quickstart",
    "section": "Where to next?",
    "text": "Where to next?\nYou have now run your first (very basic) agent! Congrats! 🎉🎉🎉\nNext, you can explore:\n\nTool Use\nStructured Output\nLayered (multi-agent) Systems\nStreaming & Events\nDatabase Management\nRAG Example\n… plus lots more! See the menu on the left.",
    "crumbs": [
      "🚀 Quickstart"
    ]
  },
  {
    "objectID": "what_is_an_agent/type_agentrun.html",
    "href": "what_is_an_agent/type_agentrun.html",
    "title": "The AgentRun type",
    "section": "",
    "text": "The AgentRun type is the core data structure in Lasagna AI. It represents what the agent generated. It serves as both the input and output format for agents, enabling seamless composition and layering.\n# This page will use the following imports:\nfrom lasagna import AgentRun, Model, EventCallback, Message\nfrom lasagna import recursive_extract_messages, flat_messages\nfrom lasagna import recursive_sum_costs",
    "crumbs": [
      "🚀 Quickstart",
      "🤖 What is an Agent?",
      "The `AgentRun` type"
    ]
  },
  {
    "objectID": "what_is_an_agent/type_agentrun.html#what-is-an-agentrun",
    "href": "what_is_an_agent/type_agentrun.html#what-is-an-agentrun",
    "title": "The AgentRun type",
    "section": "What is an AgentRun?",
    "text": "What is an AgentRun?\nAn AgentRun is a TypedDict that captures an agent’s execution:\n\nwhich agent ran (agent name, model, provider)\nwhat it generated (messages, structured data, or downstream AgentRuns)\n\nIndeed, the AgentRun data structure is recursive! That is, an AgentRun can contain other AgentRuns. This recursive nature reflects the execution path of layered agents (i.e., when an agent uses another agent during its execution).",
    "crumbs": [
      "🚀 Quickstart",
      "🤖 What is an Agent?",
      "The `AgentRun` type"
    ]
  },
  {
    "objectID": "what_is_an_agent/type_agentrun.html#the-four-types-of-agentrun",
    "href": "what_is_an_agent/type_agentrun.html#the-four-types-of-agentrun",
    "title": "The AgentRun type",
    "section": "The Four Types of AgentRun",
    "text": "The Four Types of AgentRun\nThe AgentRun type is a Union of four different execution patterns:\n\nfrom lasagna import (\n    # These are the unioned types:\n    AgentRunMessageList,\n    AgentRunParallel,\n    AgentRunChained,\n    AgentRunExtraction,\n)\n\n\n1. AgentRunMessageList — Standard Conversation\nThis is the most common type — a simple conversation between human and AI.\n\nsimple_conversation: AgentRunMessageList = {\n    \"type\": \"messages\",\n    \"agent\": \"my_chat_agent\",  # ← agent name can be anything you want!\n    \"messages\": [\n        {\"role\": \"human\", \"text\": \"Hello!\"},\n        {\"role\": \"ai\", \"text\": \"Hi there! How can I help?\"},\n    ],\n}\n\n\n\n2. AgentRunParallel — Concurrent Execution\nUsed when an agent spawns multiple sub-agents to work simultaneously (in parallel).\n\nparallel_subagents: AgentRunParallel = {\n    \"type\": \"parallel\",\n    \"agent\": \"committee_agent\",  # ← agent name can be anything you want!\n    \"runs\": [\n        # Multiple AgentRuns that executed in parallel:\n        # {...}, {...}, {...}\n    ],\n}\n\n\n\n3. AgentRunChained — Sequential Execution\nUsed when an agent coordinates a sequence of sub-agents (“chained subagents”).\n\nchained_subagents: AgentRunChained = {\n    \"type\": \"chain\",\n    \"agent\": \"pipeline_agent\",  # ← agent name can be anything you want!\n    \"runs\": [\n        # AgentRuns that executed one after another:\n        # {...}, {...}, {...}\n    ],\n}\n\n\n\n4. AgentRunExtraction — Structured Output\nUsed when an agent extracts structured data from its input.\n\nextracted_info: AgentRunExtraction = {\n    \"type\": \"extraction\",\n    \"agent\": \"data_extractor\",  # ← agent name can be anything you want!\n    \"messages\": [\n        # Model's generated messages will be here.\n        # Consider this an implementation detail; see the `result` below\n        # for the actual \"extraction result\".\n    ],\n    \"result\": {\n        # This is the payload that was extracted:\n        \"name\": \"John Doe\",\n        \"email\": \"john@example.com\", \n        \"age\": 30,\n    },\n}",
    "crumbs": [
      "🚀 Quickstart",
      "🤖 What is an Agent?",
      "The `AgentRun` type"
    ]
  },
  {
    "objectID": "what_is_an_agent/type_agentrun.html#patterns",
    "href": "what_is_an_agent/type_agentrun.html#patterns",
    "title": "The AgentRun type",
    "section": "Patterns",
    "text": "Patterns\nMuch of your job writing code that uses Lasagna will be “wrapping” and “unwrapping” AgentRun objects. Each agent must:\n\nConsider the AgentRuns it has as input.\n(zero, one, or more times) Invoke its model to generate new messages.\n(zero, one, or more times) Invoke downstream agents.\nWrap those messages (from step 2) and/or downstream AgentRuns (from step 3) into a new AgentRun and return it.\n\nLet’s discuss this pattern and give some helper functions along the way!\n\nAgent Composition Pattern\nThe AgentRun type enables Lasagna’s core composition pattern. Recall the standard agent signature:\n\nasync def my_agent(\n    model: Model,\n    event_callback: EventCallback,\n    prev_runs: list[AgentRun],  # ← Input: previous AgentRuns\n) -&gt; AgentRun:                  # ← Output: new AgentRun\n    # Agent logic here... normally you'd do something with `prev_runs`.\n    return {\n        \"type\": \"messages\",\n        \"agent\": \"my_agent\",\n        \"messages\": [\n            {\"role\": \"ai\", \"text\": \"Hi there! How can I help?\"},\n        ],\n    }\n\nThis pattern allows agents to:\n\nBuild on previous work by analyzing prev_runs.\nChain together by passing outputs as inputs to next agents.\nCompose into larger systems through layering and delegation.\n\n\n\nRecursive Extract Messages\nSince an AgentRun can be a recursive data structure, yet models require a flattened list of messages, there’s a convenience function to recursively extract all the messages found in an AgentRun:\n\nrecursive_extract_messages([simple_conversation], from_tools=False, from_extraction=False)\n\n[{'role': 'human', 'text': 'Hello!'},\n {'role': 'ai', 'text': 'Hi there! How can I help?'}]\n\n\n\n\nWrap Messages into an AgentRun\nIt is common that you have a list of messages that you want to return as an AgentRun, so there’s a simple convenience function for that as well!\n\nmessages: list[Message] = [\n    {\"role\": \"human\", \"text\": \"Hello!\"},\n    {\"role\": \"ai\", \"text\": \"Hi there! How can I help?\"},\n]\n\nflat_messages('my_agent', messages)\n\n{'agent': 'my_agent',\n 'type': 'messages',\n 'messages': [{'role': 'human', 'text': 'Hello!'},\n  {'role': 'ai', 'text': 'Hi there! How can I help?'}]}\n\n\n\n\nPut it all together!\nUsing the patterns above, we’ve derived the “most basic agent” from the Quickstart. Recall, this agent is very simple:\n\nIt extracts all previous messages.\nPasses those messages to the model, which generates new messages.\nReturns those new messages as an AgentRun.\n\n\nasync def my_basic_agent(\n    model: Model,\n    event_callback: EventCallback,\n    prev_runs: list[AgentRun],\n) -&gt; AgentRun:\n    messages = recursive_extract_messages(prev_runs, from_tools=False, from_extraction=False)\n    new_messages = await model.run(event_callback, messages, tools=[])\n    this_run = flat_messages('my_agent', new_messages)\n    return this_run",
    "crumbs": [
      "🚀 Quickstart",
      "🤖 What is an Agent?",
      "The `AgentRun` type"
    ]
  },
  {
    "objectID": "what_is_an_agent/type_agentrun.html#other-benefits-of-the-agentrun-type",
    "href": "what_is_an_agent/type_agentrun.html#other-benefits-of-the-agentrun-type",
    "title": "The AgentRun type",
    "section": "Other Benefits of the AgentRun type",
    "text": "Other Benefits of the AgentRun type\n\nCanonized Message Representations 😇\nThe AgentRun type provides a standardized format for representing any agent execution, regardless of which agent or which underlying model was invoked. Whether your agent is a simple chatbot or a complex multi-agent system, it all gets represented in the same consistent format.\nThis canonization means:\n\nType safety: Static analysis catches mismatches at development time! See Intro to Type Hints if you’re new to static type checking.\nModel swapping: You can swap providers or models at any point; data types will stay the same! See Model-swap Example.\nLayering: You can develop an agent as the root, then later on use it as a subagent. See Layering.\n\n\n\nToken Count Preservation\nUnlike other AI frameworks, Lasagna AI meticulously tracks token usage throughout your entire agent system. Token counts are preserved inside every AgentRun, no matter how many layers of agents you stack.\nEach Message within an AgentRun can include cost information:\n\nthis_run: AgentRun = {\n    \"type\": \"messages\",\n    \"agent\": \"my_agent\",\n    \"messages\": [\n        {\n            \"role\": \"ai\",\n            \"text\": \"Hi there! How can I help?\",\n            \"cost\": {\n                \"input_tokens\": 150,\n                \"output_tokens\": 75, \n                \"total_tokens\": 225,\n            },\n        },\n    ],\n}\n\nWhy this matters:\n\nAccurate billing: Know exactly what each agent execution costs.\nPerformance optimization: Identify expensive operations in complex systems.\nBudget management: Set limits and track usage across layered agents.\nNo surprises: Token counts don’t get lost in multi-agent workflows.\n\nHere is a convenient helper function to recursively sum the cost across an entire AgentRun:\n\nrecursive_sum_costs(this_run)\n\n{'input_tokens': 150, 'output_tokens': 75, 'total_tokens': 225}\n\n\n\n\nImmutable by Design\nAgentRun follows functional-programming principles — once created, it never changes. This provides:\n\nThread and coroutine safety: No race conditions in concurrent environments.\nPredictable behavior: No surprise modifications to debug.\n\n\n\nJSON Serializable\nSince AgentRun is a TypedDict, it’s just a Python dict at runtime:\n\nDatabase storage: Store directly in JSON columns or document stores.\nAPI communication: Send over HTTP/WebSocket without complicated serialization.\nCaching: Easy to cache and retrieve from Redis, memcached, etc.\nLogging: Human-readable, and can be pretty printed into logs.\n\n\n\n\n\n\n\nDatabase Storage\n\n\n\nThe AgentRun type makes database storage easy. See Database Management for more information.\n\n\n\n\n\n\n\n\nBest of two worlds!\n\n\n\nYou can have both streaming and easy database storage. See Streaming & Events for how to stream, which is an independent feature, so you can have both!",
    "crumbs": [
      "🚀 Quickstart",
      "🤖 What is an Agent?",
      "The `AgentRun` type"
    ]
  },
  {
    "objectID": "agent_features/layering.html",
    "href": "agent_features/layering.html",
    "title": "Layered (multi-agent) Systems",
    "section": "",
    "text": "# 🚧 Under Construction 🏗️\n\nThe key idea: Agents for your agents!",
    "crumbs": [
      "🚀 Quickstart",
      "⚙️ Agent Features",
      "Layered (multi-agent) Systems"
    ]
  },
  {
    "objectID": "agent_features/recursive_agent.html",
    "href": "agent_features/recursive_agent.html",
    "title": "Recursive Agent",
    "section": "",
    "text": "# 🚧 Under Construction 🏗️\n\nEver wanted a recursive agent? Now you can have one! 🤯",
    "crumbs": [
      "🚀 Quickstart",
      "⚙️ Agent Features",
      "Recursive Agent"
    ]
  },
  {
    "objectID": "agent_features/structured_output.html",
    "href": "agent_features/structured_output.html",
    "title": "Structured Output",
    "section": "",
    "text": "Structured output (aka “extraction”) is the most powerful way to leverage generative AI. 💪\n# This page will use the following imports:\n\nfrom lasagna import Model, EventCallback, AgentRun\nfrom lasagna import (\n    extract_last_message,\n    extraction,\n    flat_messages,\n    noop_callback,\n)\nfrom lasagna import known_models\nfrom lasagna.tui import tui_input_loop\n\nimport os\n\nfrom pydantic import BaseModel, Field\n\nfrom dotenv import load_dotenv\nWe need to set up our “binder” (see the quickstart guide for what this is).\nload_dotenv()\n\nif os.environ.get('OPENAI_API_KEY'):\n    print('Using OpenAI')\n    binder = known_models.BIND_OPENAI_gpt_4o()\n\nelif os.environ.get('ANTHROPIC_API_KEY'):\n    print('Using Anthropic')\n    binder = known_models.BIND_ANTHROPIC_claude_sonnet_4()\n\nelse:\n    assert False, \"Neither OPENAI_API_KEY nor ANTHROPIC_API_KEY is set! We need at least one to do this demo.\"\n\nUsing OpenAI",
    "crumbs": [
      "🚀 Quickstart",
      "⚙️ Agent Features",
      "Structured Output"
    ]
  },
  {
    "objectID": "agent_features/structured_output.html#the-power-of-structured-output",
    "href": "agent_features/structured_output.html#the-power-of-structured-output",
    "title": "Structured Output",
    "section": "The Power of Structured Output",
    "text": "The Power of Structured Output\nConsider this…\n\nThe most popular agentic use-case right now is Retrieval Augmented Generation (RAG).\nRAG is just an example of tool calling.\nTool calling is just an example of structured output.\n\nStructured output is the real hero behind the agentic revolution that is to come. 🤯🤯🤯",
    "crumbs": [
      "🚀 Quickstart",
      "⚙️ Agent Features",
      "Structured Output"
    ]
  },
  {
    "objectID": "agent_features/structured_output.html#about-grammars",
    "href": "agent_features/structured_output.html#about-grammars",
    "title": "Structured Output",
    "section": "About Grammars",
    "text": "About Grammars\nGenerative models that support grammar-restricted generation are the best at doing structured output. Such models guarantee that your specified output schema* will be adhered to.\n\n\n\n\n\n\n* Schema != Content\n\n\n\nWhile formal grammars guarantee that output schemas are followed, that should not be confused with correct output.\nFor example, if the schema says that age should be extracted as an integer, then you can be sure you’ll get an age as an integer. But it may not be the correct value!\nStill, grammars are much better than no grammars, so you’ll want to favor generative AI models that can follow a grammar.",
    "crumbs": [
      "🚀 Quickstart",
      "⚙️ Agent Features",
      "Structured Output"
    ]
  },
  {
    "objectID": "agent_features/structured_output.html#structured-output-in-lasagna-ai",
    "href": "agent_features/structured_output.html#structured-output-in-lasagna-ai",
    "title": "Structured Output",
    "section": "Structured Output in Lasagna AI",
    "text": "Structured Output in Lasagna AI\nIn Lasagna AI, you specify your desired output schema as a combination of Pydantic types and TypedDict types.\nHere’s an example, using Pydantic types:\n\nclass LinguisticConstruction(BaseModel):\n    subject: str = Field(description='the linguistic subject of the construction')\n    verb: str    = Field(description='the linguistic verb of the construction')\n    object: str  = Field(description='the linguistic object of the construction')\n\nclass ExtractionModel(BaseModel):\n    summary: str\n    constructions: list[LinguisticConstruction]\n\n\n\n\n\n\n\nWe Recommend Pydantic\n\n\n\nPydantic types are preferred over TypedDict, because they let you pass string descriptions to each parameter (which, in turn, go into the model’s prompt).\n\n\nThen, inside your agent, you pass your desired output type to model.extract(...).\nSee an example agent below:\n\nasync def linguistic_extraction_agent(\n    model: Model,\n    event_callback: EventCallback,\n    prev_runs: list[AgentRun],\n) -&gt; AgentRun:\n    # Get **ONLY** the last message from the user:\n    last_message = extract_last_message(prev_runs, from_tools=False, from_extraction=False)\n    assert last_message['role'] == 'human'\n\n    # Do structured output over the user's message:\n    new_message, result = await model.extract(\n        event_callback,\n        messages = [last_message],\n        extraction_type = ExtractionModel,\n    )\n    assert isinstance(result, ExtractionModel)\n\n    # Wrap the new messages into an `AgentRun` result:\n    return extraction('linguistic_extraction_agent', [new_message], result)\n\n\nPROMPT = \"\"\"\nHey diddle diddle,\nThe cat and the fiddle,\nThe cow jumped over the moon;\nThe little dog laughed\nTo see such sport,\nAnd the dish ran away with the spoon.\n\"\"\".strip()\n\nprev_runs: list[AgentRun] = [\n    flat_messages(\n        'input',\n        [\n            {\n                'role': 'human',\n                'text': PROMPT,\n            },\n        ],\n    ),\n]\n\nbound_agent = binder(linguistic_extraction_agent)\n\nagent_run = await bound_agent(noop_callback, prev_runs)  # type: ignore[top-level-await]\n\nassert agent_run['type'] == 'extraction'\nresult = agent_run['result']\nassert isinstance(result, ExtractionModel)\n\nprint(type(result))\nprint(result.summary)\n\nfor construction in result.constructions:\n    print('   ', construction)\n\n&lt;class '__main__.ExtractionModel'&gt;\nA whimsical poem describing a cat with a fiddle, a cow jumping over the moon, a laughing dog, and a dish running away with a spoon.\n    subject='The cow' verb='jumped' object='over the moon'\n    subject='The little dog' verb='laughed' object='To see such sport'\n    subject='The dish' verb='ran away' object='with the spoon'",
    "crumbs": [
      "🚀 Quickstart",
      "⚙️ Agent Features",
      "Structured Output"
    ]
  },
  {
    "objectID": "agent_features/structured_output.html#easy-extraction",
    "href": "agent_features/structured_output.html#easy-extraction",
    "title": "Structured Output",
    "section": "Easy Extraction",
    "text": "Easy Extraction\nThe steps above are designed such that you can layer agents. There’s a lot of “wrapping” and “unwrapping” that goes on.\nHowever, that can be overkill if you only want a simple (“easy”) extraction method.\nHere’s an “easy” way to do it, if you don’t care about building complex layered agents:\n\n# TODO",
    "crumbs": [
      "🚀 Quickstart",
      "⚙️ Agent Features",
      "Structured Output"
    ]
  },
  {
    "objectID": "agent_features/structured_output.html#more-opining-on-structured-output",
    "href": "agent_features/structured_output.html#more-opining-on-structured-output",
    "title": "Structured Output",
    "section": "More Opining on Structured Output",
    "text": "More Opining on Structured Output\nRobust software often starts with sane data formats, from which logic flows naturally. Think SQL schemas. Think algebraic data types.\nStructured output is similar in spirit. You begin with the output schema, and you build your prompt around that.",
    "crumbs": [
      "🚀 Quickstart",
      "⚙️ Agent Features",
      "Structured Output"
    ]
  },
  {
    "objectID": "agent_features/tools.html",
    "href": "agent_features/tools.html",
    "title": "Tool Use",
    "section": "",
    "text": "Give your agents superpowers! 💪\nTools let your agents interact with the outside world.\nIn Lasagna AI, tools are simply Python callables (i.e. functions or callable objects) that you pass to the AI model. The framework handles the complex orchestration of:\n# This page will use the following imports:\n\nfrom lasagna import Model, EventCallback, AgentRun\nfrom lasagna import (\n    recursive_extract_messages,\n    override_system_prompt,\n    flat_messages,\n)\nfrom lasagna import known_models\nfrom lasagna.tui import tui_input_loop\n\nimport os\n\nimport sympy as sp  # type: ignore\n\nfrom dotenv import load_dotenv\nWe need to set up our “binder” (see the quickstart guide for what this is).\nload_dotenv()\n\nif os.environ.get('OPENAI_API_KEY'):\n    print('Using OpenAI')\n    binder = known_models.BIND_OPENAI_gpt_4o()\n\nelif os.environ.get('ANTHROPIC_API_KEY'):\n    print('Using Anthropic')\n    binder = known_models.BIND_ANTHROPIC_claude_sonnet_4()\n\nelse:\n    assert False, \"Neither OPENAI_API_KEY nor ANTHROPIC_API_KEY is set! We need at least one to do this demo.\"\n\nUsing OpenAI",
    "crumbs": [
      "🚀 Quickstart",
      "⚙️ Agent Features",
      "Tool Use"
    ]
  },
  {
    "objectID": "agent_features/tools.html#create-your-first-tool",
    "href": "agent_features/tools.html#create-your-first-tool",
    "title": "Tool Use",
    "section": "Create Your First Tool",
    "text": "Create Your First Tool\nLet’s make a tool! Remember, tools are just Python callables.\nAI models (at the time of writing) are bad at math. Here’s a simple math tool to give our AI the ability to evaluate complex math expressions accurately.\n\ndef evaluate_math_expression(expression: str) -&gt; float:\n    \"\"\"\n    This tool evaluates a math expression and returns the result.\n    Pass math expression as a string, for example:\n     - \"3 * 6 + 1\"\n     - \"cos(2 * pi / 3) + log(8)\"\n     - \"(4.5/2) + (6.3/1.2)\"\n     - ... etc\n\n    :param: expression: str: the math expression to evaluate\n    \"\"\"\n    expr = sp.sympify(expression)\n    result = float(expr.evalf())\n    return result\n\n\n\n\n\n\n\nDocstring Format\n\n\n\nThe format of the docstring is important! We’ll cover this in a later section!\n\n\n\nPass the Tool to the AI Model\nIt is your agent’s job to decide which tools the AI has access to. When your agent does model.run(...), it passes zero or more tools to the AI model. Here’s a quick demo!\n\nasync def math_agent(\n    model: Model,\n    event_callback: EventCallback,\n    prev_runs: list[AgentRun],\n) -&gt; AgentRun:\n    messages = recursive_extract_messages(prev_runs, from_tools=False, from_extraction=False)\n    messages = override_system_prompt(messages, 'You are a math assistant.')\n\n    new_messages = await model.run(\n        event_callback,\n        messages,\n        tools=[\n            evaluate_math_expression,   # &lt;-- 🔨 the tool is passed here!\n        ],\n    )\n\n    return flat_messages('math_agent', new_messages)\n\n\nawait tui_input_loop(binder(math_agent))   # type: ignore[top-level-await]\n\n\n&gt;  Hi!\n\n\n\n\n\nHello! How can I assist you today?\n\n\n\n\n\n&gt;  Who are you?\n\n\n\n\n\nI'm your math assistant, here to help you with calculations, solve math problems, evaluate expressions, and more! Let me know how I can assist. 😊\n\n\n\n\n\n&gt;  What is pi to the pi? (no latex)\n\n\n\n\n\nevaluate_math_expression({\"expression\":\"pi ** pi\"})\n\n -&gt; 36.46215960720791\n\nPi raised to the power of pi is approximately 36.4622.\n\n\n\n\n\n&gt;  exit",
    "crumbs": [
      "🚀 Quickstart",
      "⚙️ Agent Features",
      "Tool Use"
    ]
  },
  {
    "objectID": "agent_features/tools.html#tool-features",
    "href": "agent_features/tools.html#tool-features",
    "title": "Tool Use",
    "section": "Tool Features",
    "text": "Tool Features\n\nDefinition Flexibilities\nTools can be either functions or callable objects (classes with __call__ method).\nAlso, tools can either be sync or async. Lasagna is natively async, so there’s a preference for async tools; but, if you pass a synchronous tool then Lasagna will run it in a thread pool (no worries).\n\n\nDocstrings\nYour tool’s docstring is critically important. It is used to:\n\nDescribe to the AI what the tool does and when to use it.\nDefine the tool’s input parameters. Each parameter has a name, type, and description!\n\nIt is formatted like this (for a tool with n input parameters):\n\"\"\"\n{tool_description}\n\n:param: {param_1_name}: {param_1_type}: {param_1_description}\n:param: {param_2_name}: {param_2_type}: {param_2_description}\n  ...\n:param: {param_n_name}: {param_n_type}: {param_n_description}\n\"\"\"\n\n\n\n\n\n\nAuthoring Tools is Prompt Engineering!\n\n\n\nYou should spend LOTS of time and energy writing your tool’s docstring. The AI depends on you describing exactly how your tool works, when to use it, and what the parameters represent.\nYou’ll likely want to iterate and test different tool docstrings to see which perform best.\n\n\nThe following types are supported as parameters of tools:\n\nstr\nfloat\nint\nbool\nenum {A} {B} ... {Z} (i.e. enum types list the enum string values as a space-separated list following the word “enum”)\n\nParameters can be optional by putting the string “(optional)” at the start of the parameter’s description in the docstring.\n\n\n\n\n\n\nLasagna will Validate Your Tool’s Parameters\n\n\n\nLasagna will check that your tool’s docstring’s parameter definitions match the callable’s actual parameters (names and types). It will also ensure that all “(optional)” parameters have default values in the callable’s signature.\nIf any docstring-to-signature mismatch is found, you’ll get a runtime exception when you first attempt to pass the tool to a model.\n\n\n\n\nParallel Execution\nIf the AI model asks for more than one tool call, then Lasagna will call those tools in parallel! This provides a speed boost, but keep this in mind so that you manage state correctly (i.e. no race conditions). If you are a well-behaved functional-style programmer who never modifies state, you’ll be fine.",
    "crumbs": [
      "🚀 Quickstart",
      "⚙️ Agent Features",
      "Tool Use"
    ]
  },
  {
    "objectID": "agent_features/tools.html#tool-recipes",
    "href": "agent_features/tools.html#tool-recipes",
    "title": "Tool Use",
    "section": "Tool Recipes",
    "text": "Tool Recipes\nMany of the recipes show examples of tool use. See:\n\nRAG Example\nInternet Research Example\nTwilio SMS Example",
    "crumbs": [
      "🚀 Quickstart",
      "⚙️ Agent Features",
      "Tool Use"
    ]
  },
  {
    "objectID": "agent_features/tools.html#layered-agents",
    "href": "agent_features/tools.html#layered-agents",
    "title": "Tool Use",
    "section": "Layered Agents",
    "text": "Layered Agents\nLayered agents are a founding idea behind the Lasagna AI library. With Lasagna, we can call agents like we call functions in procedural programming. Consider good-ol’ functions:\n\nYou define a function.\nYou can invoke it.\nOther functions can also invoke it.\nIt can invoke other functions.\nEach function has its own well-defined input/output and behavior.\n\nIn Lasagna, agents are the same!\n\nYou define an agent (as a function or callable object).\nYou can invoke it.\nOther agents can also invoke it.\nIt can invoke other agents.\nEach agent has its own well-defined input/output and behavior.\n\nJust like you compose a program by layering functions from low-level to high-level, you do the same with Lasagna and AI Agents!\n🎉🎉🎉 This is why it’s called Lasagna! Because it has layers! 🤓🤓🤓\n\nAgents as Tools\nA similar founding idea was that you should be able to layer agents by passing agents as tools to other agents. So, you can!\nSee the Layered Agents recipe for a working example.",
    "crumbs": [
      "🚀 Quickstart",
      "⚙️ Agent Features",
      "Tool Use"
    ]
  },
  {
    "objectID": "agent_features/tools.html#next-steps",
    "href": "agent_features/tools.html#next-steps",
    "title": "Tool Use",
    "section": "Next Steps",
    "text": "Next Steps\nNow that you understand tools, you can explore:\n\nStructured Output: How your agents can extract structured data\nLayered Agents: Methods for layering agents in Lasagna AI",
    "crumbs": [
      "🚀 Quickstart",
      "⚙️ Agent Features",
      "Tool Use"
    ]
  },
  {
    "objectID": "providers/aws_bedrock.html",
    "href": "providers/aws_bedrock.html",
    "title": "AWS Bedrock Models",
    "section": "",
    "text": "See: AWS Bedrock source docs\n\n# 🚧 Under Construction 🏗️",
    "crumbs": [
      "🚀 Quickstart",
      "🔌 Model Providers",
      "AWS Bedrock Models"
    ]
  },
  {
    "objectID": "providers/ollama.html",
    "href": "providers/ollama.html",
    "title": "Ollama Models",
    "section": "",
    "text": "See: Ollama source docs\n\n# 🚧 Under Construction 🏗️",
    "crumbs": [
      "🚀 Quickstart",
      "🔌 Model Providers",
      "Ollama Models"
    ]
  },
  {
    "objectID": "recipes/committee.html",
    "href": "recipes/committee.html",
    "title": "Committee Example",
    "section": "",
    "text": "# 🚧 Under Construction 🏗️\n\nEasily build committees!",
    "crumbs": [
      "🚀 Quickstart",
      "😋 Recipes",
      "Committee Example"
    ]
  },
  {
    "objectID": "recipes/rag.html",
    "href": "recipes/rag.html",
    "title": "RAG Example",
    "section": "",
    "text": "Simple RAG: Everyone’s favorite tool: Retrieval Augmented Generation (RAG). Let’s GO! 📚💨\n\n# 🚧 Under Construction 🏗️",
    "crumbs": [
      "🚀 Quickstart",
      "😋 Recipes",
      "RAG Example"
    ]
  },
  {
    "objectID": "recipes/sms.html",
    "href": "recipes/sms.html",
    "title": "Twilio SMS Example",
    "section": "",
    "text": "# 🚧 Under Construction 🏗️",
    "crumbs": [
      "🚀 Quickstart",
      "😋 Recipes",
      "Twilio SMS Example"
    ]
  },
  {
    "objectID": "recipes/parallelize.html",
    "href": "recipes/parallelize.html",
    "title": "Parallelization Example",
    "section": "",
    "text": "# 🚧 Under Construction 🏗️\n\nParallelize all the things!",
    "crumbs": [
      "🚀 Quickstart",
      "😋 Recipes",
      "Parallelization Example"
    ]
  },
  {
    "objectID": "recipes/vision.html",
    "href": "recipes/vision.html",
    "title": "Vision Example",
    "section": "",
    "text": "# 🚧 Under Construction 🏗️\n\nLasagna AI supports vision! (when using a multimodal models)",
    "crumbs": [
      "🚀 Quickstart",
      "😋 Recipes",
      "Vision Example"
    ]
  },
  {
    "objectID": "why_lasagna_ai/lasagna_vs_llamaindex.html",
    "href": "why_lasagna_ai/lasagna_vs_llamaindex.html",
    "title": "Lasagna vs LlamaIndex",
    "section": "",
    "text": "Aspect\nLasagna AI\nLlamaIndex\n\n\n\n\nParadigm\nFunctional-first\nOOP-first\n\n\nData Flow\nImmutable AgentRun structures\nMutable indexes and engines\n\n\nComposition\nAgent layering\nQuery engine chaining\n\n\nType Safety\n100% type hinted\nMixed type coverage\n\n\nAsync Support\nAsync-first architecture\nAdded async support over time\n\n\nProduction Focus\nDesigned for production\nAdded production features later\n\n\nEcosystem Size\nSmaller, focused\nLarge, comprehensive\n\n\nCore Focus\nAgent composition\nData orchestration\n\n\nPrimary Use Case\nMulti-agent workflows\nRAG and knowledge retrieval\n\n\nCore Abstraction\nAgent (composable callable)\nIndex + QueryEngine\n\n\nMental Model\n“Compose agents like functions”\n“Connect LLMs to data sources”",
    "crumbs": [
      "🚀 Quickstart",
      "❤️ Why Lasagna AI?",
      "Lasagna vs LlamaIndex"
    ]
  },
  {
    "objectID": "why_lasagna_ai/lasagna_vs_llamaindex.html#quick-comparison",
    "href": "why_lasagna_ai/lasagna_vs_llamaindex.html#quick-comparison",
    "title": "Lasagna vs LlamaIndex",
    "section": "",
    "text": "Aspect\nLasagna AI\nLlamaIndex\n\n\n\n\nParadigm\nFunctional-first\nOOP-first\n\n\nData Flow\nImmutable AgentRun structures\nMutable indexes and engines\n\n\nComposition\nAgent layering\nQuery engine chaining\n\n\nType Safety\n100% type hinted\nMixed type coverage\n\n\nAsync Support\nAsync-first architecture\nAdded async support over time\n\n\nProduction Focus\nDesigned for production\nAdded production features later\n\n\nEcosystem Size\nSmaller, focused\nLarge, comprehensive\n\n\nCore Focus\nAgent composition\nData orchestration\n\n\nPrimary Use Case\nMulti-agent workflows\nRAG and knowledge retrieval\n\n\nCore Abstraction\nAgent (composable callable)\nIndex + QueryEngine\n\n\nMental Model\n“Compose agents like functions”\n“Connect LLMs to data sources”",
    "crumbs": [
      "🚀 Quickstart",
      "❤️ Why Lasagna AI?",
      "Lasagna vs LlamaIndex"
    ]
  },
  {
    "objectID": "why_lasagna_ai/lasagna_vs_llamaindex.html#architectural-philosophy",
    "href": "why_lasagna_ai/lasagna_vs_llamaindex.html#architectural-philosophy",
    "title": "Lasagna vs LlamaIndex",
    "section": "Architectural Philosophy",
    "text": "Architectural Philosophy\nLasagna AI: Agent-Centric + Functional\n\nDesigned around agent composition - building simple agents and layering them into complex systems\nFunctional programming approach with immutable data structures\nEverything flows through standardized AgentRun types\n“Build focused agents, compose them into multi-agent systems”\n\nLlamaIndex: Data-Centric + Object-Oriented\n\nDesigned around data orchestration - connecting LLMs to data sources efficiently\nObject-oriented approach with inheritance hierarchies\nFocus on indexing, retrieval, and query patterns\n“Index your data, query it intelligently”",
    "crumbs": [
      "🚀 Quickstart",
      "❤️ Why Lasagna AI?",
      "Lasagna vs LlamaIndex"
    ]
  },
  {
    "objectID": "why_lasagna_ai/lasagna_vs_llamaindex.html#core-abstractions",
    "href": "why_lasagna_ai/lasagna_vs_llamaindex.html#core-abstractions",
    "title": "Lasagna vs LlamaIndex",
    "section": "Core Abstractions",
    "text": "Core Abstractions\nLasagna AI:\n\nAgent: Composable callable with standard signature (model, callback, prev_runs) -&gt; AgentRun\nAgentRun: Immutable, recursive data structure capturing execution results\nModel binding: Separates agent logic from model choice\nAgent routing, delegation, and specialization patterns\n\nLlamaIndex:\n\nIndex: Data structure for organizing and retrieving information\nQueryEngine: Interface for answering questions over indexed data\nChatEngine: Conversational interface with memory\nDocument processing, embedding, and retrieval pipelines",
    "crumbs": [
      "🚀 Quickstart",
      "❤️ Why Lasagna AI?",
      "Lasagna vs LlamaIndex"
    ]
  },
  {
    "objectID": "why_lasagna_ai/lasagna_vs_llamaindex.html#design-patterns",
    "href": "why_lasagna_ai/lasagna_vs_llamaindex.html#design-patterns",
    "title": "Lasagna vs LlamaIndex",
    "section": "Design Patterns",
    "text": "Design Patterns\nLasagna AI:\n\nFunctional composition - agents as pure functions\nImmutable data flow - AgentRun structures never change\nType-first design - static analysis catches integration errors\nRecursive execution tracking - full visibility into agent call trees\n\nLlamaIndex:\n\nService-oriented architecture - indexes and engines as services\nInheritance hierarchies - different index types extend base classes\nMutable state management - indexes and engines maintain state\nPipeline patterns - data flows through processing stages",
    "crumbs": [
      "🚀 Quickstart",
      "❤️ Why Lasagna AI?",
      "Lasagna vs LlamaIndex"
    ]
  },
  {
    "objectID": "why_lasagna_ai/lasagna_vs_llamaindex.html#production-readiness",
    "href": "why_lasagna_ai/lasagna_vs_llamaindex.html#production-readiness",
    "title": "Lasagna vs LlamaIndex",
    "section": "Production Readiness",
    "text": "Production Readiness\nLasagna AI:\n\nAsync-first architecture designed for production scalability\nComprehensive type safety (100% type hinted)\nBuilt-in cost tracking with token usage preservation\nImmutable design prevents race conditions in concurrent environments\nJSON-serializable data structures for easy storage/transmission\n\nLlamaIndex:\n\nAsync support added over time, not always consistent\nMixed type coverage - some components well-typed, others not\nCost tracking available but not as integrated\nMature ecosystem with battle-tested components\nExtensive integrations for production data sources",
    "crumbs": [
      "🚀 Quickstart",
      "❤️ Why Lasagna AI?",
      "Lasagna vs LlamaIndex"
    ]
  },
  {
    "objectID": "why_lasagna_ai/lasagna_vs_llamaindex.html#use-case-optimization",
    "href": "why_lasagna_ai/lasagna_vs_llamaindex.html#use-case-optimization",
    "title": "Lasagna vs LlamaIndex",
    "section": "Use Case Optimization",
    "text": "Use Case Optimization\nLasagna AI:\n\nComplex multi-agent workflows where different agents specialize\nAgent routing and delegation based on intent or context\nSystems requiring cost tracking across agent interactions\nProduction deployments with reliability and observability needs\nScenarios where agents need to coordinate, split tasks, or work in parallel\n\nLlamaIndex:\n\nRAG (Retrieval Augmented Generation) over document collections\nKnowledge base question-answering systems\nDocument processing and indexing pipelines\nData ingestion from various sources (PDFs, databases, APIs)\nQuery-response patterns over structured and unstructured data",
    "crumbs": [
      "🚀 Quickstart",
      "❤️ Why Lasagna AI?",
      "Lasagna vs LlamaIndex"
    ]
  },
  {
    "objectID": "why_lasagna_ai/lasagna_vs_llamaindex.html#trade-offs",
    "href": "why_lasagna_ai/lasagna_vs_llamaindex.html#trade-offs",
    "title": "Lasagna vs LlamaIndex",
    "section": "Trade-offs",
    "text": "Trade-offs\n\nLasagna AI Advantages\n\n✅ Superior multi-agent coordination - natural composition patterns\n✅ Type safety catches errors at development time\n✅ Clean functional architecture - easier to reason about complex flows\n✅ Built-in observability - comprehensive cost and execution tracking\n✅ Production-first design - async, immutable, reliable\n✅ Model flexibility - easy to swap providers without changing agent logic\n\n\n\nLasagna AI Disadvantages\n\n❌ Smaller ecosystem for data connectors and integrations\n❌ Learning curve for functional programming paradigm\n❌ Limited RAG tooling compared to LlamaIndex’s specialized features\n❌ Less mature document processing and indexing capabilities\n\n\n\nLlamaIndex Advantages\n\n✅ Specialized for RAG - best-in-class retrieval and indexing\n✅ Rich data ecosystem - connectors for every data source imaginable\n✅ Mature document processing - PDFs, tables, images, structured data\n✅ Advanced retrieval - hybrid search, re-ranking, query transformations\n✅ Large community and extensive documentation\n✅ Familiar patterns for developers with OOP background\n\n\n\nLlamaIndex Disadvantages\n\n❌ Complex multi-agent coordination - not the primary design focus\n❌ Mutable state issues in complex concurrent scenarios\n❌ Inconsistent async patterns across the large codebase\n❌ Less type safety - more runtime errors possible",
    "crumbs": [
      "🚀 Quickstart",
      "❤️ Why Lasagna AI?",
      "Lasagna vs LlamaIndex"
    ]
  },
  {
    "objectID": "why_lasagna_ai/lasagna_vs_llamaindex.html#when-to-choose-each",
    "href": "why_lasagna_ai/lasagna_vs_llamaindex.html#when-to-choose-each",
    "title": "Lasagna vs LlamaIndex",
    "section": "When to Choose Each",
    "text": "When to Choose Each\n\nChoose Lasagna AI When:\n🤖 Multi-Agent Systems: You need different AI agents to specialize, coordinate, and delegate tasks\n🏗️ Complex Workflows: Your system involves routing, parallel processing, or sophisticated agent interactions\n🏢 Production Reliability: You’re building enterprise systems that need predictable behavior and observability\n💰 Cost Visibility: You need detailed tracking of AI usage costs across complex agent hierarchies\n🔧 Type Safety: You want to catch integration errors at development time, not runtime\n⚡ High Concurrency: Your system needs to handle many simultaneous agent operations safely\n\n\nChoose LlamaIndex When:\n📚 RAG is Primary Use Case: You’re building question-answering systems over document collections\n🗂️ Rich Data Sources: You need to index data from many different formats and systems\n🔍 Advanced Retrieval: You need sophisticated search, re-ranking, or query transformation capabilities\n📄 Document Processing: Your system heavily involves PDFs, tables, images, or structured documents\n🚀 Rapid Prototyping: You want to quickly build and test RAG applications\n🌐 Ecosystem Breadth: You need pre-built integrations with vector databases, embedding models, etc.",
    "crumbs": [
      "🚀 Quickstart",
      "❤️ Why Lasagna AI?",
      "Lasagna vs LlamaIndex"
    ]
  },
  {
    "objectID": "why_lasagna_ai/lasagna_vs_llamaindex.html#the-bottom-line",
    "href": "why_lasagna_ai/lasagna_vs_llamaindex.html#the-bottom-line",
    "title": "Lasagna vs LlamaIndex",
    "section": "The Bottom Line",
    "text": "The Bottom Line\nLasagna AI was designed for the multi-agent future - where you have specialized AI agents that need to coordinate complex workflows. It prioritizes clean composition patterns and production reliability.\nLlamaIndex was designed for the RAG present - where you need to connect LLMs to your data sources efficiently. It prioritizes rich data integrations and retrieval sophistication.\nThe fundamental question is what you’re building:\n\nBuilding a multi-agent system where agents route, delegate, and coordinate? → Lasagna AI\nBuilding a knowledge retrieval system over documents and data sources? → LlamaIndex\n\nNote: There is overlap in the RAG space where both could work, but: - LlamaIndex will give you more sophisticated retrieval out-of-the-box - Lasagna AI will give you cleaner patterns if your RAG system needs complex agent coordination\nBoth are excellent tools that solve different problems well. The choice depends on whether your primary complexity is in agent coordination (Lasagna) or data orchestration (LlamaIndex).\n__\nDisclaimer: This comparison was AI-generated based on the documentation of both libraries, then modified slightly to fix formatting.",
    "crumbs": [
      "🚀 Quickstart",
      "❤️ Why Lasagna AI?",
      "Lasagna vs LlamaIndex"
    ]
  },
  {
    "objectID": "deployment/database.html",
    "href": "deployment/database.html",
    "title": "Database Management",
    "section": "",
    "text": "# 🚧 Under Construction 🏗️\n\nDon’t rage when trying to store raw messages and token counts. 😡 🤬\nLasagna AI makes it easy to store raw messages (for any potential debugging that needs to happen down the road), token counts, and conversation histories into your database.",
    "crumbs": [
      "🚀 Quickstart",
      "☁️ How to Deploy",
      "Database Management"
    ]
  }
]