{
 "cells": [
  {
   "cell_type": "raw",
   "id": "91257ef6-8e7c-41a4-bb80-08153da1f007",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"Structured Output\"\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54e72302-4243-4f42-a0fc-911c409f7211",
   "metadata": {},
   "source": [
    "Structured output (aka \"extraction\") is the **most powerful** way to leverage generative AI. ðŸ’ª"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d54e0b1a-eb2c-4c4d-9f6b-5af5797ad883",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This page will use the following imports:\n",
    "\n",
    "from lasagna import Model, EventCallback, AgentRun\n",
    "from lasagna import (\n",
    "    extract_last_message,\n",
    "    extraction,\n",
    "    flat_messages,\n",
    "    noop_callback,\n",
    "    easy_extract,\n",
    ")\n",
    "from lasagna import known_models\n",
    "from lasagna.tui import tui_input_loop\n",
    "\n",
    "import os\n",
    "\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6a008be-66e1-4737-9e48-8e9114ede361",
   "metadata": {},
   "source": [
    "We need to set up our \"binder\" (see the [quickstart guide](../quickstart.ipynb) for what this is)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "55353a41-2c4a-48a9-83b9-27cd6edb9964",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using OpenAI\n"
     ]
    }
   ],
   "source": [
    "load_dotenv()\n",
    "\n",
    "if os.environ.get('OPENAI_API_KEY'):\n",
    "    print('Using OpenAI')\n",
    "    binder = known_models.BIND_OPENAI_gpt_4o()\n",
    "\n",
    "elif os.environ.get('ANTHROPIC_API_KEY'):\n",
    "    print('Using Anthropic')\n",
    "    binder = known_models.BIND_ANTHROPIC_claude_sonnet_4()\n",
    "\n",
    "else:\n",
    "    assert False, \"Neither OPENAI_API_KEY nor ANTHROPIC_API_KEY is set! We need at least one to do this demo.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66d4a1d5-7924-4144-ba21-5acf27e3a551",
   "metadata": {},
   "source": [
    "## The Power of Structured Output\n",
    "\n",
    "Consider this...\n",
    "\n",
    "- The most popular _agentic_ use-case right now is _Retrieval Augmented Generation_ (RAG).\n",
    "- _RAG_ is just an example of _tool calling_.\n",
    "- _Tool calling_ is just an example of _structured output_.\n",
    "\n",
    "**Structured output is the real hero behind the _agentic_ revolution that is to come.** ðŸ¤¯ðŸ¤¯ðŸ¤¯"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c2331d4-2201-473f-98ad-06a77c052691",
   "metadata": {},
   "source": [
    "<img src=\"../assets/Set Diagram.svg\" style=\"max-width: 300px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90115c8b-1a18-471c-99f3-eaab2443ad81",
   "metadata": {},
   "source": [
    "## About Grammars\n",
    "\n",
    "Generative models that support grammar-restricted generation are the **best** at doing structured output. Such models _guarantee_ that your specified output schema\\* will be adhered to."
   ]
  },
  {
   "cell_type": "raw",
   "id": "a0fe1623-b0a1-4fb5-9a53-3d5c55bcc99d",
   "metadata": {},
   "source": [
    "::: {.callout-warning}\n",
    "## \\* Schema != Content\n",
    "\n",
    "While [formal grammars](https://en.wikipedia.org/wiki/Formal_grammar) guarantee that output schemas are followed, that should not be confused with _correct_ output.\n",
    "\n",
    "For example, if the schema says that `age` should be extracted as an integer, then you can be sure you'll get an `age` as an integer. But it may not be the correct _value_!\n",
    "\n",
    "Still, grammars are much better than no grammars, so you'll want to favor generative AI models that can follow a grammar.\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1d3471f-fe4e-4f47-9684-a399d88a33d4",
   "metadata": {},
   "source": [
    "## Structured Output in Lasagna AI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dfa3ef2-c4ad-422f-82e3-fb95c342da5f",
   "metadata": {},
   "source": [
    "In Lasagna AI, you specify your desired output schema as a combination of Pydantic types and `TypedDict` types.\n",
    "\n",
    "Here's an example, using Pydantic types:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eb8583d8-3815-4abc-b5a7-dec324ac9c6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinguisticConstruction(BaseModel):\n",
    "    subject: str = Field(description='the linguistic subject of the construction')\n",
    "    verb: str    = Field(description='the linguistic verb of the construction')\n",
    "    object: str  = Field(description='the linguistic object of the construction')\n",
    "\n",
    "class ExtractionModel(BaseModel):\n",
    "    summary: str\n",
    "    constructions: list[LinguisticConstruction]"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a35194e2-6aec-46aa-9d7d-058f0be2aed0",
   "metadata": {},
   "source": [
    "::: {.callout-warning}\n",
    "## We Recommend Pydantic\n",
    "\n",
    "Pydantic types are preferred over `TypedDict`, because they let you pass string descriptions to each parameter (which, in turn, go into the model's prompt).\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "629fecce-407d-47d7-b263-880416331254",
   "metadata": {},
   "source": [
    "Then, inside your agent, you pass your desired output type to `model.extract(...)`.\n",
    "\n",
    "See an example agent below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3c0e1a12-fa30-484b-8e7f-56420b0401d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def linguistic_extraction_agent(\n",
    "    model: Model,\n",
    "    event_callback: EventCallback,\n",
    "    prev_runs: list[AgentRun],\n",
    ") -> AgentRun:\n",
    "    # Get **ONLY** the last message from the user:\n",
    "    last_message = extract_last_message(prev_runs, from_tools=False, from_extraction=False)\n",
    "    assert last_message['role'] == 'human'\n",
    "\n",
    "    # Do structured output over the user's message:\n",
    "    new_message, result = await model.extract(\n",
    "        event_callback,\n",
    "        messages = [last_message],\n",
    "        extraction_type = ExtractionModel,\n",
    "    )\n",
    "    assert isinstance(result, ExtractionModel)\n",
    "\n",
    "    # Wrap the new messages into an `AgentRun` result:\n",
    "    return extraction('linguistic_extraction_agent', [new_message], result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dd9c0ff0-46fe-4500-b16b-e8ba200c0911",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROMPT = \"\"\"\n",
    "Hey diddle diddle,\n",
    "The cat and the fiddle,\n",
    "The cow jumped over the moon;\n",
    "The little dog laughed\n",
    "To see such sport,\n",
    "And the dish ran away with the spoon.\n",
    "\"\"\".strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a317d432-15e2-4a60-84ef-464a378435e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class '__main__.ExtractionModel'>\n",
      "A whimsical poem describing a cat with a fiddle, a cow jumping over the moon, a laughing dog, and a dish running away with a spoon.\n",
      "    subject='The cow' verb='jumped' object='over the moon'\n",
      "    subject='The little dog' verb='laughed' object='To see such sport'\n",
      "    subject='The dish' verb='ran away' object='with the spoon'\n"
     ]
    }
   ],
   "source": [
    "prev_runs: list[AgentRun] = [\n",
    "    flat_messages(\n",
    "        'input',\n",
    "        [\n",
    "            {\n",
    "                'role': 'human',\n",
    "                'text': PROMPT,\n",
    "            },\n",
    "        ],\n",
    "    ),\n",
    "]\n",
    "\n",
    "bound_agent = binder(linguistic_extraction_agent)\n",
    "\n",
    "agent_run = await bound_agent(noop_callback, prev_runs)  # type: ignore[top-level-await]\n",
    "\n",
    "assert agent_run['type'] == 'extraction'\n",
    "result = agent_run['result']\n",
    "assert isinstance(result, ExtractionModel)\n",
    "\n",
    "print(type(result))\n",
    "print(result.summary)\n",
    "\n",
    "for construction in result.constructions:\n",
    "    print('   ', construction)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2880939e-a17b-45e6-926a-d2a4e3d32243",
   "metadata": {},
   "source": [
    "## Easy Extraction\n",
    "\n",
    "The steps above are designed such that you can _layer_ agents. There's a lot of \"wrapping\" and \"unwrapping\" that goes on.\n",
    "\n",
    "However, that can be overkill if you only want a _simple_ (\"easy\") extraction method.\n",
    "\n",
    "Here's an \"easy\" way to do it, if you don't care about building complex layered agents:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bd84a28c-4377-463d-b68b-8d187fe3552a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class '__main__.ExtractionModel'>\n",
      "This is a whimsical nursery rhyme featuring anthropomorphized characters engaged in playful and surreal activities.\n",
      "    subject='The cow' verb='jumped over' object='the moon'\n",
      "    subject='The little dog' verb='laughed' object='to see such sport'\n",
      "    subject='The dish' verb='ran away with' object='the spoon'\n"
     ]
    }
   ],
   "source": [
    "result = await easy_extract(binder, PROMPT, ExtractionModel)\n",
    "\n",
    "assert isinstance(result, ExtractionModel)\n",
    "\n",
    "print(type(result))\n",
    "print(result.summary)\n",
    "\n",
    "for construction in result.constructions:\n",
    "    print('   ', construction)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0005194-e18a-4681-80a3-4f5c4c121e03",
   "metadata": {},
   "source": [
    "## More Opining on Structured Output\n",
    "\n",
    "Robust software often starts with sane data formats, from which logic flows naturally. Think SQL schemas. Think [algebraic data types](https://en.wikipedia.org/wiki/Algebraic_data_type).\n",
    "\n",
    "Structured output is similar in spirit. You begin with the output schema, and you build your prompt around that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6b5cb4d-b375-412d-8101-647a540a79cf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
