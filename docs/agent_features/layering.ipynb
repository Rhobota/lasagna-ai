{
 "cells": [
  {
   "cell_type": "raw",
   "id": "9b9966d8-e8a3-420a-807d-e562cec309db",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"Layered (multi-agent) Systems\"\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6c1e714-a32e-4afa-8a04-b9cc3c2b4e6d",
   "metadata": {},
   "source": [
    "**Agents for your agents!**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da50129e-786e-4573-a585-8557cd9a9640",
   "metadata": {},
   "source": [
    "There are two main ways to layer agents together into a multi-agent system:\n",
    "\n",
    "1. Agents as Tools\n",
    "2. Agent Routing\n",
    "\n",
    "We'll discuss each in their own sections below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9e6a7441-3c36-4c4c-9cc1-04532c7f8522",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This page will use the following imports:\n",
    "\n",
    "from lasagna import Model, EventCallback, AgentRun\n",
    "from lasagna import (\n",
    "    recursive_extract_messages,\n",
    "    override_system_prompt,\n",
    "    flat_messages,\n",
    "    extraction,\n",
    "    chained_runs,\n",
    "    BoundAgentCallable,\n",
    ")\n",
    "from lasagna import known_models\n",
    "from lasagna.tui import tui_input_loop\n",
    "\n",
    "from pydantic import BaseModel, Field\n",
    "from enum import Enum\n",
    "\n",
    "import os\n",
    "\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b41377a7-d37c-4f66-b981-f23db8a46047",
   "metadata": {},
   "source": [
    "We need to set up our \"binder\" (see the [quickstart guide](../quickstart.ipynb) for what this is)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cb773ffd-bd3b-48de-b2da-eeac26bc2a73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Anthropic\n"
     ]
    }
   ],
   "source": [
    "load_dotenv()\n",
    "\n",
    "if os.environ.get('ANTHROPIC_API_KEY'):\n",
    "    print('Using Anthropic')\n",
    "    binder = known_models.anthropic_claude_sonnet_4_5_binder\n",
    "\n",
    "elif os.environ.get('OPENAI_API_KEY'):\n",
    "    print('Using OpenAI')\n",
    "    binder = known_models.openai_gpt_5_mini_binder\n",
    "\n",
    "else:\n",
    "    assert False, \"Neither OPENAI_API_KEY nor ANTHROPIC_API_KEY is set! We need at least one to do this demo.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ef0c90f-34c7-4197-ab3b-0c605aa6a7de",
   "metadata": {},
   "source": [
    "## Agents as Tools\n",
    "\n",
    "The simplest way to combine agents is to pass one (or more) agents as \"tools\" to another agent.\n",
    "\n",
    "Here is a simple example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "86245aed-148e-4fea-b337-dac9dda4e8da",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def joke_specialist(\n",
    "    model: Model,\n",
    "    event_callback: EventCallback,\n",
    "    prev_runs: list[AgentRun],\n",
    ") -> AgentRun:\n",
    "    \"\"\"\n",
    "    Use this agent when the user seems discouraged and needs to feel better.\n",
    "    This tool will return the perfect joke for you to use to cheer the user up.\n",
    "    \"\"\"\n",
    "    messages = recursive_extract_messages(prev_runs, from_tools=False, from_extraction=False)\n",
    "    messages = override_system_prompt(messages, \"You are a joke-telling specialist. You always tell a joke related to the user's most recent message. Your response must contain **only** the joke.\")\n",
    "    new_messages = await model.run(event_callback, messages, tools=[])\n",
    "    return flat_messages('joke_specialist', new_messages)\n",
    "\n",
    "\n",
    "async def root_agent(\n",
    "    model: Model,\n",
    "    event_callback: EventCallback,\n",
    "    prev_runs: list[AgentRun],\n",
    ") -> AgentRun:\n",
    "    messages = recursive_extract_messages(prev_runs, from_tools=False, from_extraction=False)\n",
    "    messages = override_system_prompt(messages, 'You are a generic assistant. Answer all prompts briefly. Use your tools when necessary.')\n",
    "\n",
    "    new_messages = await model.run(\n",
    "        event_callback,\n",
    "        messages,\n",
    "        tools=[\n",
    "            joke_specialist,   # <-- ðŸ”¨ downstream agent as a tool\n",
    "        ],\n",
    "    )\n",
    "\n",
    "    return flat_messages('root_agent', new_messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7a366a5f-dfd8-46f2-ad80-40c15e01726a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m>  Hi!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[0m\u001b[0m\u001b[0mHello! How can I help you today\u001b[0m\u001b[0m?\u001b[0m\u001b[0m\u001b[0m\u001b[0m\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m>  Oh, I'm sick. :(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[0m\u001b[0m\u001b[0mI'm sorry to hear you're not\u001b[0m\u001b[0m feeling well! Being sick is\u001b[0m\u001b[0m never fun. Let\u001b[0m\u001b[0m me try to ch\u001b[0m\u001b[0meer you up a little\u001b[0m\u001b[0m bit.\u001b[0m\u001b[31mjoke_specialist(\u001b[0m\u001b[31m)\n",
      "\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0mWhy\u001b[0m\u001b[0m don't sick people ever win at poker?\u001b[0m\u001b[0m\n",
      "\n",
      "Because they always fold! \u001b[0m\u001b[0mðŸ¤§\u001b[0m\u001b[0m\u001b[0m\u001b[34m -> Why don't sick people ever win at poker?\n",
      "\n",
      "Because they always fold! ðŸ¤§\n",
      "\u001b[0m\u001b[0m\u001b[0mHere\u001b[0m\u001b[0m's a little joke to hopefully\u001b[0m\u001b[0m bring a smile to\u001b[0m\u001b[0m your face: Why don't sick people ever win at\u001b[0m\u001b[0m poker? Because they always fold! ðŸ¤§\n",
      "\n",
      "I\u001b[0m\u001b[0m hope you feel better soon! Make\u001b[0m\u001b[0m sure to get plenty of rest and stay\u001b[0m\u001b[0m hydrated. Take care of yourself!\u001b[0m\u001b[0m ðŸ’™\u001b[0m\u001b[0m\u001b[0m\u001b[0m\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m>  exit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "await tui_input_loop(binder(root_agent))   # type: ignore[top-level-await]"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d4a8bd93-afc6-44b3-8243-0030d42201ca",
   "metadata": {},
   "source": [
    "::: {.callout-note}\n",
    "## Why Two Agents?\n",
    "\n",
    "While this example is simple (and a bit contrived), it still demonstrates the correct _idea_: **Split up responsibilities between agents.**\n",
    "\n",
    "How are responsibilities split in the example above?\n",
    "\n",
    "- `root_agent()`: Identifies _when_ the user needs to be cheered up.\n",
    "- `joke_specialist()`: Identifies _how_ to cheer the user up.\n",
    "\n",
    "It's best to separate responsibilities for at least two reasons:\n",
    "\n",
    "1. **Better performance:** Invoking an AI model twice, each with a narrow goal, should boost performance (at the expense of more tokens).\n",
    "2. **Safer modification:** If you decide to _modify_ one of the agents, you can without too much fear of breaking the _other_ agents! Whereas, if this was all in a single agent, you might break the \"when\" by trying to improve the \"how\" (or vice versa). Yikes.\n",
    ":::"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d3cd6e14-692f-4890-8fc0-07309d8cc308",
   "metadata": {},
   "source": [
    "::: {.callout-note}\n",
    "## Bound vs Unbound Agents\n",
    "\n",
    "You are free to pass either _bound_ or _unbound_ agents as tools.\n",
    "\n",
    "If _bound_, it will use the bound model (of course).\n",
    "\n",
    "If _unbound_, it will use the model of the calling agent.\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6948253-2ea0-4ce7-b685-da9b27140491",
   "metadata": {},
   "source": [
    "See the [Agents as Tools](../recipes/agents_as_tools.ipynb) recipe for another example."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c355c907-2f0c-4cbd-96a3-4fc4d7a5d1a2",
   "metadata": {},
   "source": [
    "## Agent Routing\n",
    "\n",
    "The most flexible way to combine agents is to have agents delegate to one another (\"routing\"). The router agent's job is to delegate. It might delegate _wholesale_, or it might _transform_ the prompt before delegating. It might delegate to a _single_ downstream agent, or to _several_ downstream agents. This is what makes it so flexible!\n",
    "\n",
    "The recipe for routing is to combine _structured output_ with good ol' programming.\n",
    "\n",
    "Here is an example, extending the example above to be more flexible:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9aacaccb-9677-41e2-a922-2c9e6be6680c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Mood(Enum):\n",
    "    happy = 'happy'\n",
    "    sad = 'sad'\n",
    "    neutral = 'neutral'\n",
    "\n",
    "\n",
    "class MessageClassification(BaseModel):\n",
    "    thoughts: str = Field(description=\"Your free-form thoughts about the user's most recent message, and what mood the user may be in.\")\n",
    "    mood: Mood = Field(description=\"Your determination of the user's mood based on their most recent message. If it is not clear, output 'neutral'.\")\n",
    "\n",
    "\n",
    "class RouterAgent:\n",
    "    def __init__(\n",
    "        self,\n",
    "        cheer_up_agent: BoundAgentCallable,\n",
    "        default_agent: BoundAgentCallable,\n",
    "    ) -> None:\n",
    "        self.cheer_up_agent = cheer_up_agent\n",
    "        self.default_agent = default_agent\n",
    "\n",
    "    async def __call__(\n",
    "        self,\n",
    "        model: Model,\n",
    "        event_callback: EventCallback,\n",
    "        prev_runs: list[AgentRun],\n",
    "    ) -> AgentRun:\n",
    "        messages = recursive_extract_messages(prev_runs, from_tools=False, from_extraction=False)\n",
    "        messages = override_system_prompt(messages, \"You classify the user's mood.\")\n",
    "\n",
    "        message, result = await model.extract(\n",
    "            event_callback,\n",
    "            messages = messages,\n",
    "            extraction_type = MessageClassification,\n",
    "        )\n",
    "\n",
    "        extraction_run = extraction('router_agent', [message], result)\n",
    "\n",
    "        downstream_agent = (self.cheer_up_agent if result.mood == Mood.sad else self.default_agent)\n",
    "\n",
    "        downstream_run = await downstream_agent(event_callback, prev_runs)\n",
    "\n",
    "        return chained_runs('router_agent', [extraction_run, downstream_run])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "52ec3462-50c8-49c0-8d5d-b5b743437fc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m>  Hi!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[0m\u001b[0m\u001b[31mMessageClassification(\u001b[0m\u001b[31m{\"thoughts\":\u001b[0m\u001b[31m \"Th\u001b[0m\u001b[31me user sent \u001b[0m\u001b[31ma simple\u001b[0m\u001b[31m greeting \\\"\u001b[0m\u001b[31mHi!\\\" \u001b[0m\u001b[31mwhich \u001b[0m\u001b[31mis a friendl\u001b[0m\u001b[31my and posit\u001b[0m\u001b[31mive wa\u001b[0m\u001b[31my to start\u001b[0m\u001b[31m a convers\u001b[0m\u001b[31mation. There\u001b[0m\u001b[31m's nothi\u001b[0m\u001b[31mng in the\u001b[0m\u001b[31m mes\u001b[0m\u001b[31msage th\u001b[0m\u001b[31mat s\u001b[0m\u001b[31muggest\u001b[0m\u001b[31ms sa\u001b[0m\u001b[31mdnes\u001b[0m\u001b[31ms or n\u001b[0m\u001b[31megati\u001b[0m\u001b[31mvity\u001b[0m\u001b[31m, and the\u001b[0m\u001b[31m excl\u001b[0m\u001b[31mamatio\u001b[0m\u001b[31mn point \u001b[0m\u001b[31madds a b\u001b[0m\u001b[31mit of en\u001b[0m\u001b[31mthusi\u001b[0m\u001b[31masm or chee\u001b[0m\u001b[31mrful\u001b[0m\u001b[31mness\u001b[0m\u001b[31m to t\u001b[0m\u001b[31mhe\u001b[0m\u001b[31m gree\u001b[0m\u001b[31mtin\u001b[0m\u001b[31mg. Thi\u001b[0m\u001b[31ms seems \u001b[0m\u001b[31mlike a neu\u001b[0m\u001b[31mtral to sli\u001b[0m\u001b[31mgh\u001b[0m\u001b[31mtly positi\u001b[0m\u001b[31mve interac\u001b[0m\u001b[31mtion.\"\u001b[0m\u001b[31m, \"\u001b[0m\u001b[31mmood\"\u001b[0m\u001b[31m: \"hap\u001b[0m\u001b[31mpy\"}\u001b[0m\u001b[31m)\n",
      "\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0mHello! How are\u001b[0m\u001b[0m you doing today? Is\u001b[0m\u001b[0m there anything I can help you with?\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m>  Oh, I'm sick. :(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[0m\u001b[0m\u001b[31mMessageClassification(\u001b[0m\u001b[31m{\"though\u001b[0m\u001b[31mts\": \"\u001b[0m\u001b[31mThe user m\u001b[0m\u001b[31mentioned\u001b[0m\u001b[31m they a\u001b[0m\u001b[31mre sic\u001b[0m\u001b[31mk and used\u001b[0m\u001b[31m a sa\u001b[0m\u001b[31md face emo\u001b[0m\u001b[31mticon\u001b[0m\u001b[31m \\\":(\\\" wh\u001b[0m\u001b[31mic\u001b[0m\u001b[31mh cle\u001b[0m\u001b[31marly in\u001b[0m\u001b[31mdic\u001b[0m\u001b[31mates they're\u001b[0m\u001b[31m not feeli\u001b[0m\u001b[31mng well both\u001b[0m\u001b[31m phy\u001b[0m\u001b[31msically and \u001b[0m\u001b[31memotionall\u001b[0m\u001b[31my. Being s\u001b[0m\u001b[31mick t\u001b[0m\u001b[31mypically m\u001b[0m\u001b[31makes \u001b[0m\u001b[31mpeople feel \u001b[0m\u001b[31mdown, un\u001b[0m\u001b[31mco\u001b[0m\u001b[31mmfor\u001b[0m\u001b[31mtabl\u001b[0m\u001b[31me, and \u001b[0m\u001b[31munhappy. Th\u001b[0m\u001b[31me c\u001b[0m\u001b[31mombination\u001b[0m\u001b[31m of stating \u001b[0m\u001b[31mthey're\u001b[0m\u001b[31m s\u001b[0m\u001b[31mick and the \u001b[0m\u001b[31msad emoticon\u001b[0m\u001b[31m s\u001b[0m\u001b[31mtrongly\u001b[0m\u001b[31m sugges\u001b[0m\u001b[31mts a sad \u001b[0m\u001b[31mmood.\"\u001b[0m\u001b[31m, \"mo\u001b[0m\u001b[31mod\":\u001b[0m\u001b[31m \"sad\"}\u001b[0m\u001b[31m)\n",
      "\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0mOh no, I'm sorry you\u001b[0m\u001b[0m're feeling under the weather! Here's a joke to\u001b[0m\u001b[0m hopefully brighten your day:\n",
      "\n",
      "Why don\u001b[0m\u001b[0m't sick people ever win races\u001b[0m\u001b[0m?\n",
      "\n",
      "Because they're always running a\u001b[0m\u001b[0m fever! ðŸ¤’\n",
      "\n",
      "I\u001b[0m\u001b[0m hope you feel better soon! Rest\u001b[0m\u001b[0m up and take care of yourself!\u001b[0m\u001b[0m ðŸ˜Š\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m>  Thanks, bye.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[0m\u001b[0m\u001b[31mMessageClassification(\u001b[0m\u001b[31m{\"thought\u001b[0m\u001b[31ms\": \"Th\u001b[0m\u001b[31me us\u001b[0m\u001b[31mer is saying\u001b[0m\u001b[31m g\u001b[0m\u001b[31moodb\u001b[0m\u001b[31mye \u001b[0m\u001b[31mwith a sim\u001b[0m\u001b[31mple \\\"Tha\u001b[0m\u001b[31mnks, bye.\u001b[0m\u001b[31m\\\" \u001b[0m\u001b[31mThi\u001b[0m\u001b[31ms ap\u001b[0m\u001b[31mpear\u001b[0m\u001b[31ms to be a \u001b[0m\u001b[31mpolit\u001b[0m\u001b[31me but\u001b[0m\u001b[31m brief far\u001b[0m\u001b[31mewell.\u001b[0m\u001b[31m While they \u001b[0m\u001b[31mthank\u001b[0m\u001b[31med\u001b[0m\u001b[31m me,\u001b[0m\u001b[31m which \u001b[0m\u001b[31mcould ind\u001b[0m\u001b[31micat\u001b[0m\u001b[31me \u001b[0m\u001b[31msome appre\u001b[0m\u001b[31mciation,\u001b[0m\u001b[31m the bre\u001b[0m\u001b[31mvity an\u001b[0m\u001b[31md conte\u001b[0m\u001b[31mxt (they \u001b[0m\u001b[31mmentioned\u001b[0m\u001b[31m bein\u001b[0m\u001b[31mg sick\u001b[0m\u001b[31m e\u001b[0m\u001b[31marli\u001b[0m\u001b[31mer) \u001b[0m\u001b[31msug\u001b[0m\u001b[31mgests they m\u001b[0m\u001b[31migh\u001b[0m\u001b[31mt st\u001b[0m\u001b[31mill not be\u001b[0m\u001b[31m feelin\u001b[0m\u001b[31mg great. H\u001b[0m\u001b[31mowever,\u001b[0m\u001b[31m t\u001b[0m\u001b[31mhe \\\"than\u001b[0m\u001b[31mks\\\" does sh\u001b[0m\u001b[31mow some grat\u001b[0m\u001b[31mitude f\u001b[0m\u001b[31mor the joke \u001b[0m\u001b[31mI shared. O\u001b[0m\u001b[31mverall, this\u001b[0m\u001b[31m seems lik\u001b[0m\u001b[31me a neutral \u001b[0m\u001b[31mfarewell\u001b[0m\u001b[31m - not parti\u001b[0m\u001b[31mcular\u001b[0m\u001b[31mly happy \u001b[0m\u001b[31mor sad,\u001b[0m\u001b[31m just\u001b[0m\u001b[31m a standard \u001b[0m\u001b[31mgoodbye.\"\u001b[0m\u001b[31m, \"mo\u001b[0m\u001b[31mod\": \"neu\u001b[0m\u001b[31mtral\"}\u001b[0m\u001b[31m)\n",
      "\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0mYou're welcome! Take\u001b[0m\u001b[0m care an\u001b[0m\u001b[0md get well\u001b[0m\u001b[0m soon! \u001b[0m\u001b[0mðŸŒŸ\u001b[0m\u001b[0m\n",
      "\n",
      "Bye! ðŸ‘‹\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m>  exit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "async def joke_telling_agent(\n",
    "    model: Model,\n",
    "    event_callback: EventCallback,\n",
    "    prev_runs: list[AgentRun],\n",
    ") -> AgentRun:\n",
    "    messages = recursive_extract_messages(prev_runs, from_tools=False, from_extraction=False)\n",
    "    messages = override_system_prompt(messages, \"You are a joke-telling specialist. You always tell a joke related to the user's most recent message. Cheer the user up by telling a joke!\")\n",
    "    new_messages = await model.run(event_callback, messages, tools=[])\n",
    "    return flat_messages('joke_telling_agent', new_messages)\n",
    "\n",
    "\n",
    "async def generic_agent(\n",
    "    model: Model,\n",
    "    event_callback: EventCallback,\n",
    "    prev_runs: list[AgentRun],\n",
    ") -> AgentRun:\n",
    "    messages = recursive_extract_messages(prev_runs, from_tools=False, from_extraction=False)\n",
    "    messages = override_system_prompt(messages, \"You are a helpful assistant.\")\n",
    "    new_messages = await model.run(event_callback, messages, tools=[])\n",
    "    return flat_messages('generic_agent', new_messages)\n",
    "\n",
    "\n",
    "my_agent = RouterAgent(\n",
    "    cheer_up_agent = binder(joke_telling_agent),\n",
    "    default_agent = binder(generic_agent),\n",
    ")\n",
    "\n",
    "\n",
    "await tui_input_loop(binder(my_agent))   # type: ignore[top-level-await]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc841357-d06f-444c-bba2-2c6f18c9d365",
   "metadata": {},
   "source": [
    "See the [Agent Routing](../recipes/routing_agent.ipynb) recipe for a working example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25abf2a3-f56a-4de5-b7ce-5a83b2c2b233",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
