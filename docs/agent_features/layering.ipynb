{
 "cells": [
  {
   "cell_type": "raw",
   "id": "9b9966d8-e8a3-420a-807d-e562cec309db",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"Layered (multi-agent) Systems\"\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6c1e714-a32e-4afa-8a04-b9cc3c2b4e6d",
   "metadata": {},
   "source": [
    "**Agents for your agents!**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da50129e-786e-4573-a585-8557cd9a9640",
   "metadata": {},
   "source": [
    "There are two main ways to layer agents together into a multi-agent system:\n",
    "\n",
    "1. Agents as Tools\n",
    "2. Agent Routing\n",
    "\n",
    "We'll discuss each in their own sections below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9e6a7441-3c36-4c4c-9cc1-04532c7f8522",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This page will use the following imports:\n",
    "\n",
    "from lasagna import Model, EventCallback, AgentRun\n",
    "from lasagna import (\n",
    "    recursive_extract_messages,\n",
    "    override_system_prompt,\n",
    "    flat_messages,\n",
    "    extraction,\n",
    "    chained_runs,\n",
    "    BoundAgentCallable,\n",
    ")\n",
    "from lasagna import known_models\n",
    "from lasagna.tui import tui_input_loop\n",
    "\n",
    "from pydantic import BaseModel, Field\n",
    "from enum import Enum\n",
    "\n",
    "import os\n",
    "\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b41377a7-d37c-4f66-b981-f23db8a46047",
   "metadata": {},
   "source": [
    "We need to set up our \"binder\" (see the [quickstart guide](../quickstart.ipynb) for what this is)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cb773ffd-bd3b-48de-b2da-eeac26bc2a73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using OpenAI\n"
     ]
    }
   ],
   "source": [
    "load_dotenv()\n",
    "\n",
    "if os.environ.get('OPENAI_API_KEY'):\n",
    "    print('Using OpenAI')\n",
    "    binder = known_models.openai_gpt_4o_binder\n",
    "\n",
    "elif os.environ.get('ANTHROPIC_API_KEY'):\n",
    "    print('Using Anthropic')\n",
    "    binder = known_models.anthropic_claude_sonnet_4_binder\n",
    "\n",
    "else:\n",
    "    assert False, \"Neither OPENAI_API_KEY nor ANTHROPIC_API_KEY is set! We need at least one to do this demo.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ef0c90f-34c7-4197-ab3b-0c605aa6a7de",
   "metadata": {},
   "source": [
    "## Agents as Tools\n",
    "\n",
    "The simplest way to combine agents is to pass one (or more) agents as \"tools\" to another agent.\n",
    "\n",
    "Here is a simple example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "86245aed-148e-4fea-b337-dac9dda4e8da",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def joke_specialist(\n",
    "    model: Model,\n",
    "    event_callback: EventCallback,\n",
    "    prev_runs: list[AgentRun],\n",
    ") -> AgentRun:\n",
    "    \"\"\"\n",
    "    Use this agent when the user seems discouraged and needs to feel better.\n",
    "    This tool will return the perfect joke to cheer the user up.\n",
    "    \"\"\"\n",
    "    messages = recursive_extract_messages(prev_runs, from_tools=False, from_extraction=False)\n",
    "    messages = override_system_prompt(messages, \"You are a joke-telling specialist. You always tell a joke related to the user's most recent message. Your response must contain **only** the joke.\")\n",
    "    new_messages = await model.run(event_callback, messages, tools=[])\n",
    "    return flat_messages('joke_specialist', new_messages)\n",
    "\n",
    "\n",
    "async def root_agent(\n",
    "    model: Model,\n",
    "    event_callback: EventCallback,\n",
    "    prev_runs: list[AgentRun],\n",
    ") -> AgentRun:\n",
    "    messages = recursive_extract_messages(prev_runs, from_tools=False, from_extraction=False)\n",
    "    messages = override_system_prompt(messages, 'You are a generic assistant. Use your tools when necessary.')\n",
    "\n",
    "    new_messages = await model.run(\n",
    "        event_callback,\n",
    "        messages,\n",
    "        tools=[\n",
    "            joke_specialist,   # <-- ðŸ”¨ downstream agent as a tool\n",
    "        ],\n",
    "    )\n",
    "\n",
    "    return flat_messages('root_agent', new_messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7a366a5f-dfd8-46f2-ad80-40c15e01726a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m>  Hi!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0mHi\u001b[0m\u001b[0m there\u001b[0m\u001b[0m!\u001b[0m\u001b[0m How\u001b[0m\u001b[0m can\u001b[0m\u001b[0m I\u001b[0m\u001b[0m help\u001b[0m\u001b[0m you\u001b[0m\u001b[0m today\u001b[0m\u001b[0m?\u001b[0m\u001b[0m\u001b[0m\u001b[0m\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m>  Oh, I'm sick. :(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[0m\u001b[0m\u001b[31mjoke_specialist(\u001b[0m\u001b[31m{}\u001b[0m\u001b[31m)\n",
      "\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0mWhy\u001b[0m\u001b[0m did\u001b[0m\u001b[0m the\u001b[0m\u001b[0m sick\u001b[0m\u001b[0m computer\u001b[0m\u001b[0m go\u001b[0m\u001b[0m to\u001b[0m\u001b[0m the\u001b[0m\u001b[0m doctor\u001b[0m\u001b[0m?\u001b[0m\u001b[0m  \n",
      "\u001b[0m\u001b[0mIt\u001b[0m\u001b[0m had\u001b[0m\u001b[0m a\u001b[0m\u001b[0m virus\u001b[0m\u001b[0m!\u001b[0m\u001b[0m\u001b[0m\u001b[34m -> Why did the sick computer go to the doctor?  \n",
      "It had a virus!\n",
      "\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0mOh\u001b[0m\u001b[0m no\u001b[0m\u001b[0m,\u001b[0m\u001b[0m I'm\u001b[0m\u001b[0m sorry\u001b[0m\u001b[0m you're\u001b[0m\u001b[0m not\u001b[0m\u001b[0m feeling\u001b[0m\u001b[0m well\u001b[0m\u001b[0m!\u001b[0m\u001b[0m Here's\u001b[0m\u001b[0m a\u001b[0m\u001b[0m little\u001b[0m\u001b[0m joke\u001b[0m\u001b[0m to\u001b[0m\u001b[0m cheer\u001b[0m\u001b[0m you\u001b[0m\u001b[0m up\u001b[0m\u001b[0m:\n",
      "\n",
      "\u001b[0m\u001b[0mWhy\u001b[0m\u001b[0m did\u001b[0m\u001b[0m the\u001b[0m\u001b[0m sick\u001b[0m\u001b[0m computer\u001b[0m\u001b[0m go\u001b[0m\u001b[0m to\u001b[0m\u001b[0m the\u001b[0m\u001b[0m doctor\u001b[0m\u001b[0m?\u001b[0m\u001b[0m  \n",
      "\u001b[0m\u001b[0mIt\u001b[0m\u001b[0m had\u001b[0m\u001b[0m a\u001b[0m\u001b[0m virus\u001b[0m\u001b[0m!\u001b[0m\u001b[0m  \n",
      "\n",
      "\u001b[0m\u001b[0mHope\u001b[0m\u001b[0m that\u001b[0m\u001b[0m brings\u001b[0m\u001b[0m at\u001b[0m\u001b[0m least\u001b[0m\u001b[0m a\u001b[0m\u001b[0m little\u001b[0m\u001b[0m smile\u001b[0m\u001b[0m.\u001b[0m\u001b[0m Feel\u001b[0m\u001b[0m better\u001b[0m\u001b[0m soon\u001b[0m\u001b[0m!\u001b[0m\u001b[0m ðŸ˜Š\u001b[0m\u001b[0m\u001b[0m\u001b[0m\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m>  exit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "await tui_input_loop(binder(root_agent))   # type: ignore[top-level-await]"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d4a8bd93-afc6-44b3-8243-0030d42201ca",
   "metadata": {},
   "source": [
    "::: {.callout-note}\n",
    "## Why Two Agents?\n",
    "\n",
    "While this example is simple (and a bit contrived), it still demonstrates the correct _idea_: **Split up responsibilities between agents.**\n",
    "\n",
    "How are responsibilities split in the example above?\n",
    "\n",
    "- `root_agent()`: Identifies _when_ the user needs to be cheered up.\n",
    "- `joke_specialist()`: Identifies _how_ to cheer the user up.\n",
    "\n",
    "It's best to separate responsibilities for at least two reasons:\n",
    "\n",
    "1. **Better performance:** Invoking an AI model twice, each with a narrow goal, should boost performance (at the expense of more tokens).\n",
    "2. **Safer modification:** If you decide to _modify_ one of the agents, you can without too much fear of breaking the _other_ agents! Whereas, if this was all in a single agent, you might break the \"when\" by trying to improve the \"how\" (or vice versa). Yikes.\n",
    ":::"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d3cd6e14-692f-4890-8fc0-07309d8cc308",
   "metadata": {},
   "source": [
    "::: {.callout-note}\n",
    "## Bound vs Unbound Agents\n",
    "\n",
    "You are free to pass either _bound_ or _unbound_ agents as tools.\n",
    "\n",
    "If _bound_, it will use the bound model (of course).\n",
    "\n",
    "If _unbound_, it will use the model of the calling agent.\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6948253-2ea0-4ce7-b685-da9b27140491",
   "metadata": {},
   "source": [
    "See the [Agents as Tools](../recipes/agents_as_tools.ipynb) recipe for another example."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c355c907-2f0c-4cbd-96a3-4fc4d7a5d1a2",
   "metadata": {},
   "source": [
    "## Agent Routing\n",
    "\n",
    "The most flexible way to combine agents is to have agents delegate to one another (\"routing\"). The router agent's job is to delegate. It might delegate _wholesale_, or it might _transform_ the prompt before delegating. It might delegate to a _single_ downstream agent, or to _several_ downstream agents. This is what makes it so flexible!\n",
    "\n",
    "The recipe for routing is to combine _structured output_ with good ol' programming.\n",
    "\n",
    "Here is an example, extending the example above to be more flexible:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9aacaccb-9677-41e2-a922-2c9e6be6680c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Mood(Enum):\n",
    "    happy = 'happy'\n",
    "    sad = 'sad'\n",
    "    neutral = 'neutral'\n",
    "\n",
    "\n",
    "class MessageClassification(BaseModel):\n",
    "    thoughts: str = Field(description=\"Your free-form thoughts about the user's most recent message, and what mood the user may be in.\")\n",
    "    mood: Mood = Field(description=\"Your determination of the user's mood based on their most recent message. If it is not clear, output 'neutral'.\")\n",
    "\n",
    "\n",
    "class RouterAgent:\n",
    "    def __init__(\n",
    "        self,\n",
    "        cheer_up_agent: BoundAgentCallable,\n",
    "        default_agent: BoundAgentCallable,\n",
    "    ) -> None:\n",
    "        self.cheer_up_agent = cheer_up_agent\n",
    "        self.default_agent = default_agent\n",
    "\n",
    "    async def __call__(\n",
    "        self,\n",
    "        model: Model,\n",
    "        event_callback: EventCallback,\n",
    "        prev_runs: list[AgentRun],\n",
    "    ) -> AgentRun:\n",
    "        messages = recursive_extract_messages(prev_runs, from_tools=False, from_extraction=False)\n",
    "        messages = override_system_prompt(messages, \"You classify the user's mood.\")\n",
    "\n",
    "        message, result = await model.extract(\n",
    "            event_callback,\n",
    "            messages = messages,\n",
    "            extraction_type = MessageClassification,\n",
    "        )\n",
    "\n",
    "        extraction_run = extraction('router_agent', message, result)\n",
    "\n",
    "        downstream_agent = (self.cheer_up_agent if result.mood == Mood.sad else self.default_agent)\n",
    "\n",
    "        downstream_run = await downstream_agent(event_callback, prev_runs)\n",
    "\n",
    "        return chained_runs('router_agent', [extraction_run, downstream_run])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "52ec3462-50c8-49c0-8d5d-b5b743437fc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m>  Hi!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[0m\u001b[0m\u001b[31mMessageClassification(\u001b[0m\u001b[31m{\"\u001b[0m\u001b[31mthought\u001b[0m\u001b[31ms\u001b[0m\u001b[31m\":\"\u001b[0m\u001b[31mThe\u001b[0m\u001b[31m user\u001b[0m\u001b[31m gre\u001b[0m\u001b[31mets\u001b[0m\u001b[31m warmly\u001b[0m\u001b[31m and\u001b[0m\u001b[31m positively\u001b[0m\u001b[31m.\u001b[0m\u001b[31m This\u001b[0m\u001b[31m usually\u001b[0m\u001b[31m reflects\u001b[0m\u001b[31m a\u001b[0m\u001b[31m happy\u001b[0m\u001b[31m or\u001b[0m\u001b[31m friendly\u001b[0m\u001b[31m mood\u001b[0m\u001b[31m.\",\"\u001b[0m\u001b[31mm\u001b[0m\u001b[31mood\u001b[0m\u001b[31m\":\"\u001b[0m\u001b[31mhappy\u001b[0m\u001b[31m\"}\u001b[0m\u001b[31m)\n",
      "\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0mHello\u001b[0m\u001b[0m!\u001b[0m\u001b[0m ðŸ˜Š\u001b[0m\u001b[0m How\u001b[0m\u001b[0m can\u001b[0m\u001b[0m I\u001b[0m\u001b[0m assist\u001b[0m\u001b[0m you\u001b[0m\u001b[0m today\u001b[0m\u001b[0m?\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m>  Oh, I'm sick. :(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[0m\u001b[0m\u001b[31mMessageClassification(\u001b[0m\u001b[31m{\"\u001b[0m\u001b[31mthought\u001b[0m\u001b[31ms\u001b[0m\u001b[31m\":\"\u001b[0m\u001b[31mThe\u001b[0m\u001b[31m user\u001b[0m\u001b[31m appears\u001b[0m\u001b[31m to\u001b[0m\u001b[31m be\u001b[0m\u001b[31m feeling\u001b[0m\u001b[31m un\u001b[0m\u001b[31mwell\u001b[0m\u001b[31m and\u001b[0m\u001b[31m sad\u001b[0m\u001b[31m based\u001b[0m\u001b[31m on\u001b[0m\u001b[31m their\u001b[0m\u001b[31m message\u001b[0m\u001b[31m.\",\"\u001b[0m\u001b[31mm\u001b[0m\u001b[31mood\u001b[0m\u001b[31m\":\"\u001b[0m\u001b[31msad\u001b[0m\u001b[31m\"}\u001b[0m\u001b[31m)\n",
      "\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0mOh\u001b[0m\u001b[0m no\u001b[0m\u001b[0m,\u001b[0m\u001b[0m I'm\u001b[0m\u001b[0m sorry\u001b[0m\u001b[0m to\u001b[0m\u001b[0m hear\u001b[0m\u001b[0m that\u001b[0m\u001b[0m!\u001b[0m\u001b[0m Here's\u001b[0m\u001b[0m a\u001b[0m\u001b[0m joke\u001b[0m\u001b[0m to\u001b[0m\u001b[0m hopefully\u001b[0m\u001b[0m nurse\u001b[0m\u001b[0m your\u001b[0m\u001b[0m spirits\u001b[0m\u001b[0m back\u001b[0m\u001b[0m to\u001b[0m\u001b[0m health\u001b[0m\u001b[0m:\u001b[0m\u001b[0m  \n",
      "\n",
      "\u001b[0m\u001b[0mWhy\u001b[0m\u001b[0m did\u001b[0m\u001b[0m the\u001b[0m\u001b[0m doctor\u001b[0m\u001b[0m carry\u001b[0m\u001b[0m a\u001b[0m\u001b[0m red\u001b[0m\u001b[0m pen\u001b[0m\u001b[0m?\u001b[0m\u001b[0m  \n",
      "\u001b[0m\u001b[0mIn\u001b[0m\u001b[0m case\u001b[0m\u001b[0m they\u001b[0m\u001b[0m needed\u001b[0m\u001b[0m to\u001b[0m\u001b[0m draw\u001b[0m\u001b[0m blood\u001b[0m\u001b[0m!\u001b[0m\u001b[0m  \n",
      "\n",
      "\u001b[0m\u001b[0mHope\u001b[0m\u001b[0m you\u001b[0m\u001b[0m feel\u001b[0m\u001b[0m better\u001b[0m\u001b[0m soon\u001b[0m\u001b[0m!\u001b[0m\u001b[0m ðŸ©º\u001b[0m\u001b[0mðŸ˜Š\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m>  Thanks!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[0m\u001b[0m\u001b[31mMessageClassification(\u001b[0m\u001b[31m{\"\u001b[0m\u001b[31mthought\u001b[0m\u001b[31ms\u001b[0m\u001b[31m\":\"\u001b[0m\u001b[31mThe\u001b[0m\u001b[31m user\u001b[0m\u001b[31m expressed\u001b[0m\u001b[31m gratitude\u001b[0m\u001b[31m but\u001b[0m\u001b[31m hasn't\u001b[0m\u001b[31m provided\u001b[0m\u001b[31m much\u001b[0m\u001b[31m emotional\u001b[0m\u001b[31m information\u001b[0m\u001b[31m in\u001b[0m\u001b[31m their\u001b[0m\u001b[31m recent\u001b[0m\u001b[31m message\u001b[0m\u001b[31m.\u001b[0m\u001b[31m Their\u001b[0m\u001b[31m mood\u001b[0m\u001b[31m toward\u001b[0m\u001b[31m me\u001b[0m\u001b[31m seems\u001b[0m\u001b[31m polite\u001b[0m\u001b[31m and\u001b[0m\u001b[31m appreciative\u001b[0m\u001b[31m,\u001b[0m\u001b[31m but\u001b[0m\u001b[31m overall\u001b[0m\u001b[31m they\u001b[0m\u001b[31m may\u001b[0m\u001b[31m still\u001b[0m\u001b[31m feel\u001b[0m\u001b[31m un\u001b[0m\u001b[31mwell\u001b[0m\u001b[31m or\u001b[0m\u001b[31m neutral\u001b[0m\u001b[31m due\u001b[0m\u001b[31m to\u001b[0m\u001b[31m being\u001b[0m\u001b[31m sick\u001b[0m\u001b[31m.\",\"\u001b[0m\u001b[31mm\u001b[0m\u001b[31mood\u001b[0m\u001b[31m\":\"\u001b[0m\u001b[31mneutral\u001b[0m\u001b[31m\"}\u001b[0m\u001b[31m)\n",
      "\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0mYou're\u001b[0m\u001b[0m welcome\u001b[0m\u001b[0m!\u001b[0m\u001b[0m ðŸ˜Š\u001b[0m\u001b[0m Rest\u001b[0m\u001b[0m up\u001b[0m\u001b[0m,\u001b[0m\u001b[0m drink\u001b[0m\u001b[0m plenty\u001b[0m\u001b[0m of\u001b[0m\u001b[0m fluids\u001b[0m\u001b[0m,\u001b[0m\u001b[0m and\u001b[0m\u001b[0m take\u001b[0m\u001b[0m care\u001b[0m\u001b[0m of\u001b[0m\u001b[0m yourself\u001b[0m\u001b[0m.\u001b[0m\u001b[0m If\u001b[0m\u001b[0m you\u001b[0m\u001b[0m need\u001b[0m\u001b[0m anything\u001b[0m\u001b[0m else\u001b[0m\u001b[0m,\u001b[0m\u001b[0m I'm\u001b[0m\u001b[0m here\u001b[0m\u001b[0m to\u001b[0m\u001b[0m help\u001b[0m\u001b[0m.\u001b[0m\u001b[0m Hope\u001b[0m\u001b[0m you\u001b[0m\u001b[0mâ€™re\u001b[0m\u001b[0m feeling\u001b[0m\u001b[0m like\u001b[0m\u001b[0m your\u001b[0m\u001b[0m fabulous\u001b[0m\u001b[0m self\u001b[0m\u001b[0m in\u001b[0m\u001b[0m no\u001b[0m\u001b[0m time\u001b[0m\u001b[0m!\u001b[0m\u001b[0m ðŸ’›\u001b[0m\u001b[0mâœ¨\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m>  exit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "async def joke_telling_agent(\n",
    "    model: Model,\n",
    "    event_callback: EventCallback,\n",
    "    prev_runs: list[AgentRun],\n",
    ") -> AgentRun:\n",
    "    messages = recursive_extract_messages(prev_runs, from_tools=False, from_extraction=False)\n",
    "    messages = override_system_prompt(messages, \"You are a joke-telling specialist. You always tell a joke related to the user's most recent message. Cheer the user up by telling a joke!\")\n",
    "    new_messages = await model.run(event_callback, messages, tools=[])\n",
    "    return flat_messages('joke_telling_agent', new_messages)\n",
    "\n",
    "\n",
    "async def generic_agent(\n",
    "    model: Model,\n",
    "    event_callback: EventCallback,\n",
    "    prev_runs: list[AgentRun],\n",
    ") -> AgentRun:\n",
    "    messages = recursive_extract_messages(prev_runs, from_tools=False, from_extraction=False)\n",
    "    messages = override_system_prompt(messages, \"You are a helpful assistant.\")\n",
    "    new_messages = await model.run(event_callback, messages, tools=[])\n",
    "    return flat_messages('generic_agent', new_messages)\n",
    "\n",
    "\n",
    "my_agent = RouterAgent(\n",
    "    cheer_up_agent = binder(joke_telling_agent),\n",
    "    default_agent = binder(generic_agent),\n",
    ")\n",
    "\n",
    "\n",
    "await tui_input_loop(binder(my_agent))   # type: ignore[top-level-await]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc841357-d06f-444c-bba2-2c6f18c9d365",
   "metadata": {},
   "source": [
    "See the [Agent Routing](../recipes/routing_agent.ipynb) recipe for a working example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25abf2a3-f56a-4de5-b7ce-5a83b2c2b233",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
