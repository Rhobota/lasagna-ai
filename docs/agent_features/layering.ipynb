{
 "cells": [
  {
   "cell_type": "raw",
   "id": "9b9966d8-e8a3-420a-807d-e562cec309db",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"Layered (multi-agent) Systems\"\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6c1e714-a32e-4afa-8a04-b9cc3c2b4e6d",
   "metadata": {},
   "source": [
    "**Agents for your agents!**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da50129e-786e-4573-a585-8557cd9a9640",
   "metadata": {},
   "source": [
    "There are two main ways to layer agents together into a multi-agent system:\n",
    "\n",
    "1. Agents as Tools\n",
    "2. Agent Routing\n",
    "\n",
    "We'll discuss each in its own section below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9e6a7441-3c36-4c4c-9cc1-04532c7f8522",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This page will use the following imports:\n",
    "\n",
    "from lasagna import Model, EventCallback, AgentRun\n",
    "from lasagna import (\n",
    "    recursive_extract_messages,\n",
    "    override_system_prompt,\n",
    "    flat_messages,\n",
    ")\n",
    "from lasagna import known_models\n",
    "from lasagna.tui import tui_input_loop\n",
    "\n",
    "import os\n",
    "\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b41377a7-d37c-4f66-b981-f23db8a46047",
   "metadata": {},
   "source": [
    "We need to set up our \"binder\" (see the [quickstart guide](../quickstart.ipynb) for what this is)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cb773ffd-bd3b-48de-b2da-eeac26bc2a73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using OpenAI\n"
     ]
    }
   ],
   "source": [
    "load_dotenv()\n",
    "\n",
    "if os.environ.get('OPENAI_API_KEY'):\n",
    "    print('Using OpenAI')\n",
    "    binder = known_models.openai_gpt_4o_binder\n",
    "\n",
    "elif os.environ.get('ANTHROPIC_API_KEY'):\n",
    "    print('Using Anthropic')\n",
    "    binder = known_models.anthropic_claude_sonnet_4_binder\n",
    "\n",
    "else:\n",
    "    assert False, \"Neither OPENAI_API_KEY nor ANTHROPIC_API_KEY is set! We need at least one to do this demo.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ef0c90f-34c7-4197-ab3b-0c605aa6a7de",
   "metadata": {},
   "source": [
    "## Agents as Tools\n",
    "\n",
    "The simplest way to combine agents is to pass one (or more) agents as \"tools\" to another agent.\n",
    "\n",
    "Here is a simple example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "86245aed-148e-4fea-b337-dac9dda4e8da",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def joke_specialist(\n",
    "    model: Model,\n",
    "    event_callback: EventCallback,\n",
    "    prev_runs: list[AgentRun],\n",
    ") -> AgentRun:\n",
    "    \"\"\"\n",
    "    Use this agent when the user seems discouraged and needs to feel better.\n",
    "    This tool will return the perfect joke to cheer the user up.\n",
    "    \"\"\"\n",
    "    messages = recursive_extract_messages(prev_runs, from_tools=False, from_extraction=False)\n",
    "    messages = override_system_prompt(messages, \"You are a joke-telling specialist. You always tell a joke related to the user's most recent message. Your response must contain **only** the joke.\")\n",
    "    new_messages = await model.run(event_callback, messages, tools=[])\n",
    "    return flat_messages('joke_specialist', new_messages)\n",
    "\n",
    "\n",
    "async def root_agent(\n",
    "    model: Model,\n",
    "    event_callback: EventCallback,\n",
    "    prev_runs: list[AgentRun],\n",
    ") -> AgentRun:\n",
    "    messages = recursive_extract_messages(prev_runs, from_tools=False, from_extraction=False)\n",
    "    messages = override_system_prompt(messages, 'You are a generic assistant. Use your tools when necessary.')\n",
    "\n",
    "    new_messages = await model.run(\n",
    "        event_callback,\n",
    "        messages,\n",
    "        tools=[\n",
    "            joke_specialist,   # <-- ðŸ”¨ downstream agent as a tool\n",
    "        ],\n",
    "    )\n",
    "\n",
    "    return flat_messages('root_agent', new_messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7a366a5f-dfd8-46f2-ad80-40c15e01726a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m>  Hi!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0mHi\u001b[0m\u001b[0m there\u001b[0m\u001b[0m!\u001b[0m\u001b[0m How\u001b[0m\u001b[0m can\u001b[0m\u001b[0m I\u001b[0m\u001b[0m assist\u001b[0m\u001b[0m you\u001b[0m\u001b[0m today\u001b[0m\u001b[0m?\u001b[0m\u001b[0m ðŸ˜Š\u001b[0m\u001b[0m\u001b[0m\u001b[0m\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m>  Oh, I'm sick. :(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0mI'm\u001b[0m\u001b[0m sorry\u001b[0m\u001b[0m to\u001b[0m\u001b[0m hear\u001b[0m\u001b[0m that\u001b[0m\u001b[0m you're\u001b[0m\u001b[0m not\u001b[0m\u001b[0m feeling\u001b[0m\u001b[0m well\u001b[0m\u001b[0m.\u001b[0m\u001b[0m Being\u001b[0m\u001b[0m sick\u001b[0m\u001b[0m is\u001b[0m\u001b[0m never\u001b[0m\u001b[0m fun\u001b[0m\u001b[0m.\u001b[0m\u001b[0m Take\u001b[0m\u001b[0m it\u001b[0m\u001b[0m easy\u001b[0m\u001b[0m,\u001b[0m\u001b[0m stay\u001b[0m\u001b[0m hydrated\u001b[0m\u001b[0m,\u001b[0m\u001b[0m and\u001b[0m\u001b[0m rest\u001b[0m\u001b[0m as\u001b[0m\u001b[0m much\u001b[0m\u001b[0m as\u001b[0m\u001b[0m you\u001b[0m\u001b[0m can\u001b[0m\u001b[0m.\u001b[0m\u001b[0m Would\u001b[0m\u001b[0m you\u001b[0m\u001b[0m like\u001b[0m\u001b[0m me\u001b[0m\u001b[0m to\u001b[0m\u001b[0m find\u001b[0m\u001b[0m a\u001b[0m\u001b[0m joke\u001b[0m\u001b[0m to\u001b[0m\u001b[0m cheer\u001b[0m\u001b[0m you\u001b[0m\u001b[0m up\u001b[0m\u001b[0m a\u001b[0m\u001b[0m bit\u001b[0m\u001b[0m?\u001b[0m\u001b[0m L\u001b[0m\u001b[0maughter\u001b[0m\u001b[0m can\u001b[0m\u001b[0m be\u001b[0m\u001b[0m great\u001b[0m\u001b[0m medicine\u001b[0m\u001b[0m!\u001b[0m\u001b[0m ðŸ˜Š\u001b[0m\u001b[0m\u001b[0m\u001b[0m\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m>  yes\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[0m\u001b[0m\u001b[31mjoke_specialist(\u001b[0m\u001b[31m{}\u001b[0m\u001b[31m)\n",
      "\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0mWhy\u001b[0m\u001b[0m did\u001b[0m\u001b[0m the\u001b[0m\u001b[0m doctor\u001b[0m\u001b[0m carry\u001b[0m\u001b[0m a\u001b[0m\u001b[0m red\u001b[0m\u001b[0m pen\u001b[0m\u001b[0m?\u001b[0m\u001b[0m  \n",
      "\u001b[0m\u001b[0mIn\u001b[0m\u001b[0m case\u001b[0m\u001b[0m they\u001b[0m\u001b[0m needed\u001b[0m\u001b[0m to\u001b[0m\u001b[0m draw\u001b[0m\u001b[0m blood\u001b[0m\u001b[0m!\u001b[0m\u001b[0m\u001b[0m\u001b[34m -> Why did the doctor carry a red pen?  \n",
      "In case they needed to draw blood!\n",
      "\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0mHere's\u001b[0m\u001b[0m a\u001b[0m\u001b[0m little\u001b[0m\u001b[0m joke\u001b[0m\u001b[0m to\u001b[0m\u001b[0m cheer\u001b[0m\u001b[0m you\u001b[0m\u001b[0m up\u001b[0m\u001b[0m:\u001b[0m\u001b[0m  \n",
      "\n",
      "\u001b[0m\u001b[0mWhy\u001b[0m\u001b[0m did\u001b[0m\u001b[0m the\u001b[0m\u001b[0m doctor\u001b[0m\u001b[0m carry\u001b[0m\u001b[0m a\u001b[0m\u001b[0m red\u001b[0m\u001b[0m pen\u001b[0m\u001b[0m?\u001b[0m\u001b[0m  \n",
      "\u001b[0m\u001b[0mIn\u001b[0m\u001b[0m case\u001b[0m\u001b[0m they\u001b[0m\u001b[0m needed\u001b[0m\u001b[0m to\u001b[0m\u001b[0m draw\u001b[0m\u001b[0m blood\u001b[0m\u001b[0m!\n",
      "\n",
      "\u001b[0m\u001b[0mHope\u001b[0m\u001b[0m that\u001b[0m\u001b[0m brought\u001b[0m\u001b[0m a\u001b[0m\u001b[0m smile\u001b[0m\u001b[0m to\u001b[0m\u001b[0m your\u001b[0m\u001b[0m face\u001b[0m\u001b[0m!\u001b[0m\u001b[0m Feel\u001b[0m\u001b[0m better\u001b[0m\u001b[0m soon\u001b[0m\u001b[0m!\u001b[0m\u001b[0m ðŸ˜Š\u001b[0m\u001b[0m\u001b[0m\u001b[0m\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m>  exit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "await tui_input_loop(binder(root_agent))   # type: ignore[top-level-await]"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d4a8bd93-afc6-44b3-8243-0030d42201ca",
   "metadata": {},
   "source": [
    "::: {.callout-note}\n",
    "## Why Two Agents?\n",
    "\n",
    "While this example is simple (and a bit contrived), it still demonstrates the correct _idea_: **Split up responsibilities between agents.**\n",
    "\n",
    "How are responsibilities split in the example above?\n",
    "\n",
    "- `root_agent()`: Identifies _when_ the user needs to be cheered up.\n",
    "- `joke_specialist()`: Identifies _how_ to cheer the user up.\n",
    "\n",
    "It's best to separate responsibilities for at least two reasons:\n",
    "\n",
    "1. **Better performance:** Invoking an AI model twice, each with a narrow goal, should boost performance (at the expense of more tokens).\n",
    "2. **Safer modification:** If you decide to _modify_ one of the agents, you can without too much fear of breaking the _other_ agents! Whereas, if this was all in a single agent, you might break the \"when\" by trying to improve the \"how\" (or vice versa). Yikes.\n",
    ":::"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d3cd6e14-692f-4890-8fc0-07309d8cc308",
   "metadata": {},
   "source": [
    "::: {.callout-note}\n",
    "## Bound vs Unbound Agents\n",
    "\n",
    "You are free to pass either _bound_ or _unbound_ agents as tools.\n",
    "\n",
    "If _bound_, it will use the bound model (of course).\n",
    "\n",
    "If _unbound_, it will use the model of the calling agent.\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6948253-2ea0-4ce7-b685-da9b27140491",
   "metadata": {},
   "source": [
    "See the [Agents as Tools](../recipes/agents_as_tools.ipynb) recipe for another example."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c355c907-2f0c-4cbd-96a3-4fc4d7a5d1a2",
   "metadata": {},
   "source": [
    "## Agent Routing\n",
    "\n",
    "TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aacaccb-9677-41e2-a922-2c9e6be6680c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52ec3462-50c8-49c0-8d5d-b5b743437fc7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97148626-84af-4761-ab42-15fa9ed7263c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cc841357-d06f-444c-bba2-2c6f18c9d365",
   "metadata": {},
   "source": [
    "See the [Agent Routing](../recipes/routing_agent.ipynb) recipe for a working example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25abf2a3-f56a-4de5-b7ce-5a83b2c2b233",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
